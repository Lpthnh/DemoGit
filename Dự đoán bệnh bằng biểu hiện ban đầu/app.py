import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTE
from mlxtend.frequent_patterns import apriori, association_rules

# T·∫Øt c·∫£nh b√°o li√™n quan ƒë·∫øn downcasting
pd.set_option('future.no_silent_downcasting', True)

# C·∫•u h√¨nh trang
st.set_page_config(page_title="·ª®ng D·ª•ng D·ª± ƒêo√°n B·ªánh", layout="wide")

# CSS ƒë·ªÉ ƒë√≥ng khung ph·∫ßn "G·ª£i √Ω h√†nh ƒë·ªông" v√† b·∫£ng lu·∫≠t k·∫øt h·ª£p
st.markdown("""
<style>
.suggestion-box {
    border: 2px solid #28a745;
    border-radius: 10px;
    padding: 15px;
    background-color: #f8fff8;
    margin-bottom: 20px;
}
.suggestion-box h4 {
    color: #28a745;
    margin-bottom: 10px;
}
.suggestion-box p {
    margin: 5px 0;
    font-size: 16px;
}
.stDataFrame table {
    width: 100%;
    border-collapse: collapse;
}
.stDataFrame th, .stDataFrame td {
    padding: 8px;
    text-align: center;
    border: 1px solid #ddd;
}
.stDataFrame th {
    background-color: #f2f2f2;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

# Ti√™u ƒë·ªÅ v√† m√¥ t·∫£
st.title("ü©∫ D·ª± ƒêo√°n B·ªánh T·ª´ Tri·ªáu Ch·ª©ng")
st.markdown("""
""")

# H√†m t√¨m b·ªánh g·∫ßn gi·ªëng nh·∫•t
def find_closest_disease(disease, reference_list):
    disease = disease.lower()
    for ref_disease in reference_list:
        ref_disease_lower = ref_disease.lower()
        if disease in ref_disease_lower or ref_disease_lower in disease:
            return ref_disease
    return None

# H√†m g·ª£i √Ω b·ªánh vi·ªán v√† h√†nh ƒë·ªông
def suggest_hospitals_and_actions(disease, hospital_df, action_dict, region):
    # T√¨m b·ªánh vi·ªán theo b·ªánh v√† khu v·ª±c
    matches = hospital_df[(hospital_df["B·ªánh"] == disease) & (hospital_df["Khu v·ª±c"] == region)]

    # N·∫øu kh√¥ng c√≥ k·∫øt qu·∫£, th·ª≠ t√¨m b·ªánh g·∫ßn gi·ªëng
    if matches.empty:
        closest_disease = find_closest_disease(disease, hospital_df["B·ªánh"].unique())
        if closest_disease:
            matches = hospital_df[(hospital_df["B·ªánh"] == closest_disease) & (hospital_df["Khu v·ª±c"] == region)]
            disease = closest_disease

    hospitals = matches["B·ªánh vi·ªán"].dropna().tolist()
    if not hospitals:
        hospitals = ["Kh√¥ng c√≥ b·ªánh vi·ªán g·ª£i √Ω trong khu v·ª±c n√†y, vui l√≤ng ƒë·∫øn c∆° s·ªü y t·∫ø g·∫ßn nh·∫•t."]

    # L·∫•y th√¥ng tin h√†nh ƒë·ªông t·ª´ action_dict, n·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c th√¨ t√¨m g·∫ßn gi·ªëng
    if disease in action_dict:
        action_info = action_dict[disease]
    else:
        closest_disease = find_closest_disease(disease, action_dict.keys())
        if closest_disease:
            action_info = action_dict[closest_disease]
        else:
            action_info = {
                "severity": "Ch∆∞a c√≥ th√¥ng tin",
                "action": "C·∫ßn tham kh·∫£o √Ω ki·∫øn b√°c sƒ© ƒë·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô nghi√™m tr·ªçng."
            }

    return hospitals, action_info["severity"], action_info["action"]


# Kh·ªüi t·∫°o session_state
if 'le_disease' not in st.session_state:
    st.session_state.le_disease = None
if 'model_results' not in st.session_state:
    st.session_state.model_results = None
if 'symptom_columns' not in st.session_state:
    st.session_state.symptom_columns = None
if 'feature_columns' not in st.session_state:
    st.session_state.feature_columns = None
if 'le_gender' not in st.session_state:
    st.session_state.le_gender = None
if 'reset_symptom_form' not in st.session_state:
    st.session_state.reset_symptom_form = False
if 'reset_cluster_form' not in st.session_state:
    st.session_state.reset_cluster_form = False
if 'clusters' not in st.session_state:
    st.session_state.clusters = None
if 'cluster_diseases' not in st.session_state:
    st.session_state.cluster_diseases = None
if 'cluster_rules' not in st.session_state:
    st.session_state.cluster_rules = None

# Hard-code g·ª£i √Ω h√†nh ƒë·ªông v√† m·ª©c ƒë·ªô nghi√™m tr·ªçng
action_dict = {
    "Nhi·ªÖm n·∫•m": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m da li·ªÖu, tu√¢n th·ªß ƒëi·ªÅu tr·ªã theo ch·ªâ ƒë·ªãnh."},
    "D·ªã ·ª©ng": {"severity": "Th·∫•p", "action": "Tr√°nh t√°c nh√¢n g√¢y d·ªã ·ª©ng, d√πng thu·ªëc theo h∆∞·ªõng d·∫´n b√°c sƒ©."},
    "Tr√†o ng∆∞·ª£c d·∫° d√†y": {"severity": "Trung b√¨nh", "action": "ƒÇn u·ªëng ƒëi·ªÅu ƒë·ªô, d√πng thu·ªëc theo ch·ªâ ƒë·ªãnh b√°c sƒ©."},
    "·ª® m·∫≠t m·∫°n t√≠nh": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m chuy√™n khoa gan m·∫≠t, tu√¢n th·ªß ch·ªâ ƒë·ªãnh."},
    "Ph·∫£n ·ª©ng thu·ªëc": {"severity": "Cao", "action": "Ng∆∞ng thu·ªëc, ƒëi kh√°m b√°c sƒ© ngay."},
    "Lo√©t d·∫° d√†y t√° tr√†ng": {"severity": "Trung b√¨nh", "action": "ƒÇn u·ªëng h·ª£p l√Ω, d√πng thu·ªëc theo ch·ªâ ƒë·ªãnh."},
    "H·ªôi ch·ª©ng suy gi·∫£m mi·ªÖn d·ªãch": {"severity": "Cao", "action": "ƒêi kh√°m chuy√™n khoa, ƒëi·ªÅu tr·ªã theo ph√°c ƒë·ªì."},
    "Ti·ªÉu ƒë∆∞·ªùng": {"severity": "Trung b√¨nh", "action": "Ki·ªÉm so√°t ƒë∆∞·ªùng huy·∫øt, tu√¢n th·ªß ch·∫ø ƒë·ªô ƒÉn v√† thu·ªëc."},
    "Vi√™m d·∫° d√†y ru·ªôt": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m chuy√™n khoa ti√™u h√≥a, ƒëi·ªÅu tr·ªã ƒë√∫ng c√°ch."},
    "Hen suy·ªÖn": {"severity": "Cao", "action": "S·ª≠ d·ª•ng thu·ªëc c·∫Øt c∆°n, ƒëi kh√°m n·∫øu kh√≥ th·ªü n·∫∑ng."},
    "TƒÉng huy·∫øt √°p": {"severity": "Trung b√¨nh", "action": "Theo d√µi huy·∫øt √°p, d√πng thu·ªëc ƒë√∫ng ch·ªâ ƒë·ªãnh."},
    "ƒêau n·ª≠a ƒë·∫ßu": {"severity": "Trung b√¨nh", "action": "Tr√°nh stress, d√πng thu·ªëc theo ch·ªâ ƒë·ªãnh."},
    "Tho√°i h√≥a ƒë·ªët s·ªëng c·ªï": {"severity": "Trung b√¨nh", "action": "V·∫≠t l√Ω tr·ªã li·ªáu, d√πng thu·ªëc gi·∫£m ƒëau."},
    "Li·ªát (xu·∫•t huy·∫øt n√£o)": {"severity": "Cao", "action": "ƒêi kh√°m ngay, ƒëi·ªÅu tr·ªã c·∫•p c·ª©u."},
    "V√†ng da": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m chuy√™n khoa gan m·∫≠t, x√©t nghi·ªám c·∫ßn thi·∫øt."},
    "S·ªët r√©t": {"severity": "Cao", "action": "ƒêi kh√°m v√† ƒëi·ªÅu tr·ªã ngay, theo d√µi s√°t."},
    "Th·ªßy ƒë·∫≠u": {"severity": "Trung b√¨nh", "action": "ChƒÉm s√≥c da, tr√°nh g√£i, ƒëi·ªÅu tr·ªã h·ªó tr·ª£."},
    "S·ªët xu·∫•t huy·∫øt": {"severity": "Cao", "action": "Theo d√µi s√°t, ƒë·∫øn c∆° s·ªü y t·∫ø n·∫øu xu·∫•t huy·∫øt."},
    "Th∆∞∆°ng h√†n": {"severity": "Cao", "action": "ƒêi kh√°m v√† ƒëi·ªÅu tr·ªã k·ªãp th·ªùi."},
    "Vi√™m gan A": {"severity": "Trung b√¨nh", "action": "Ngh·ªâ ng∆°i, theo d√µi v√† ƒëi·ªÅu tr·ªã h·ªó tr·ª£."},
    "Vi√™m gan B": {"severity": "Cao", "action": "ƒêi kh√°m chuy√™n khoa gan, ƒëi·ªÅu tr·ªã theo ph√°c ƒë·ªì."},
    "Vi√™m gan C": {"severity": "Cao", "action": "ƒêi kh√°m chuy√™n khoa gan, ƒëi·ªÅu tr·ªã theo ph√°c ƒë·ªì."},
    "Vi√™m gan D": {"severity": "Cao", "action": "ƒêi kh√°m chuy√™n khoa gan, ƒëi·ªÅu tr·ªã theo ph√°c ƒë·ªì."},
    "Vi√™m gan E": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m chuy√™n khoa gan, ƒëi·ªÅu tr·ªã h·ªó tr·ª£."},
    "Vi√™m gan do r∆∞·ª£u": {"severity": "Cao", "action": "Ng∆∞ng r∆∞·ª£u, ƒëi·ªÅu tr·ªã chuy√™n khoa gan."},
    "Lao ph·ªïi": {"severity": "Cao", "action": "ƒêi kh√°m v√† ƒëi·ªÅu tr·ªã lao theo ph√°c ƒë·ªì."},
    "C·∫£m l·∫°nh": {"severity": "Th·∫•p", "action": "Ngh·ªâ ng∆°i, d√πng thu·ªëc h·∫° s·ªët, gi·ªØ ·∫•m."},
    "Vi√™m ph·ªïi": {"severity": "Cao", "action": "ƒêi kh√°m v√† ƒëi·ªÅu tr·ªã t·∫°i b·ªánh vi·ªán."},
    "Trƒ© h·ªón h·ª£p": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m chuy√™n khoa ti√™u h√≥a."},
    "ƒêau tim": {"severity": "Cao", "action": "ƒêi kh√°m c·∫•p c·ª©u ngay n·∫øu c√≥ tri·ªáu ch·ª©ng."},
    "Gi√£n tƒ©nh m·∫°ch": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m chuy√™n khoa m·∫°ch m√°u."},
    "Suy gi√°p": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m n·ªôi ti·∫øt v√† ƒëi·ªÅu tr·ªã."},
    "C∆∞·ªùng gi√°p": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m n·ªôi ti·∫øt v√† ƒëi·ªÅu tr·ªã."},
    "H·∫° ƒë∆∞·ªùng huy·∫øt": {"severity": "Cao", "action": "ƒÇn u·ªëng k·ªãp th·ªùi, ƒëi kh√°m n·∫øu n·∫∑ng."},
    "Tho√°i h√≥a kh·ªõp": {"severity": "Trung b√¨nh", "action": "V·∫≠t l√Ω tr·ªã li·ªáu, d√πng thu·ªëc gi·∫£m ƒëau."},
    "Th·∫•p kh·ªõp": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m v√† ƒëi·ªÅu tr·ªã chuy√™n khoa."},
    "Ch√≥ng m·∫∑t": {"severity": "Th·∫•p", "action": "ƒêi kh√°m ƒë·ªÉ x√°c ƒë·ªãnh nguy√™n nh√¢n."},
    "M·ª•n tr·ª©ng c√°": {"severity": "Th·∫•p", "action": "ƒêi kh√°m da li·ªÖu, ƒëi·ªÅu tr·ªã t·∫°i ch·ªó."},
    "Nhi·ªÖm tr√πng ƒë∆∞·ªùng ti·ªÉu": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m v√† d√πng thu·ªëc theo ch·ªâ ƒë·ªãnh."},
    "V·∫£y n·∫øn": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m da li·ªÖu v√† ƒëi·ªÅu tr·ªã."},
    "Ch·ªëc l·ªü": {"severity": "Th·∫•p", "action": "Gi·ªØ v·ªá sinh, d√πng thu·ªëc theo ch·ªâ ƒë·ªãnh."}
}

# Kh·ªüi t·∫°o df v√† hospital_df m·∫∑c ƒë·ªãnh
df = pd.read_excel("data_benh.xlsx")
hospital_df = pd.read_excel("benhviengoiy.xlsx")

df.columns = df.columns.str.strip()
df.columns = df.columns.str.replace(r"\.\d+$", "", regex=True)
df = df.loc[:, ~df.columns.duplicated()]
base_cols = ['Tu·ªïi', 'Gi·ªõi t√≠nh', 'B·ªánh hi·ªán t·∫°i']
symptom_columns = [col for col in df.columns if col not in base_cols and df[col].dropna().isin([0, 1]).all()]

st.session_state.symptom_columns = symptom_columns

# Sidebar cho t·∫£i file
with st.sidebar:
    st.header("üì§ T·∫£i D·ªØ Li·ªáu")
    uploaded_files = st.file_uploader("Ch·ªçn file ƒë·ªÉ t·∫£i l√™n", accept_multiple_files=True)

    if uploaded_files and len(uploaded_files) == 2:
        df_file = None
        hospital_file = None
        for file in uploaded_files:
            if "data_benh" in file.name.lower():
                df_file = file
            elif "benhviengoiy" in file.name.lower():
                hospital_file = file
        
        if df_file and hospital_file:
            df = pd.read_excel(df_file)
            hospital_df = pd.read_excel(hospital_file)
            st.success("T·∫£i 2 file th√†nh c√¥ng!")
            
            df.columns = df.columns.str.strip()
            df.columns = df.columns.str.replace(r"\.\d+$", "", regex=True)
            df = df.loc[:, ~df.columns.duplicated()]
            base_cols = ['Tu·ªïi', 'Gi·ªõi t√≠nh', 'B·ªánh hi·ªán t·∫°i']
            symptom_columns = [col for col in df.columns if col not in base_cols and df[col].dropna().isin([0, 1]).all()]

            st.session_state.symptom_columns = symptom_columns

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu to√†n c·ª•c
df['Gi·ªõi t√≠nh'] = df['Gi·ªõi t√≠nh'].astype(str).str.strip()
gender_mapping = {'0': 'Nam', '1': 'N·ªØ'}
valid_values = ['0', '1', 'Nam', 'N·ªØ']
if not df['Gi·ªõi t√≠nh'].isin(valid_values).all():
    invalid_genders = df[~df['Gi·ªõi t√≠nh'].isin(valid_values)]['Gi·ªõi t√≠nh'].unique()
    st.error(f"C·ªôt 'Gi·ªõi t√≠nh' ch·ª©a c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá: {invalid_genders}. Ch·ªâ ch·∫•p nh·∫≠n '0', '1', 'Nam', ho·∫∑c 'N·ªØ'.")
    st.stop()
df['Gi·ªõi t√≠nh'] = df['Gi·ªõi t√≠nh'].replace(gender_mapping)

le_gender = LabelEncoder()
df['Gi·ªõi t√≠nh'] = le_gender.fit_transform(df['Gi·ªõi t√≠nh'])
st.session_state.le_gender = le_gender

le_disease = LabelEncoder()
df['B·ªánh hi·ªán t·∫°i'] = le_disease.fit_transform(df['B·ªánh hi·ªán t·∫°i'].astype(str))
st.session_state.le_disease = le_disease

base_cols = ['Tu·ªïi', 'Gi·ªõi t√≠nh', 'B·ªánh hi·ªán t·∫°i']
binary_cols = [col for col in df.columns if df[col].dropna().isin([0, 1]).all() and col not in base_cols]

known_symptoms = [
    "S·ªët", "Ho", "ƒêau h·ªçng", "Kh√≥ th·ªü", "Ch·∫£y n∆∞·ªõc m≈©i", "Ngh·∫πt m≈©i", "ƒêau ƒë·∫ßu",
    "ƒêau ng·ª±c", "M·ªát m·ªèi", "Bu·ªìn n√¥n", "N√¥n", "Ti√™u ch·∫£y", "T√°o b√≥n", "ƒêau b·ª•ng",
    "·ªön l·∫°nh", "Ph√°t ban", "Ng·ª©a da", "Ch√≥ng m·∫∑t", "M·∫•t v·ªã gi√°c", "M·∫•t kh·ª©u gi√°c",
    "Lo √¢u", "Kh√≥ ng·ªß", "Kh√≥ nu·ªët", "S·ª•t c√¢n", "ƒê·ªï m·ªì h√¥i nhi·ªÅu"
]

base_cols = ['Tu·ªïi', 'Gi·ªõi t√≠nh', 'B·ªánh hi·ªán t·∫°i']
symptom_columns = [col for col in binary_cols]
feature_columns = ['Tu·ªïi', 'Gi·ªõi t√≠nh'] + symptom_columns
st.session_state.feature_columns = feature_columns

# X√≥a c√°c m·∫´u b·ªã tr√πng ho√†n to√†n trong d·ªØ li·ªáu
df_no_dup = df.drop_duplicates()
#df_no_dup.to_csv("final_benh_dataset.csv", index=False)

# T·∫°o c√°c tab
tab1, tab2, tab3, tab4 = st.tabs(["üìä Ph√¢n t√≠ch d·ªØ li·ªáu", "ü§ñ D·ª± ƒëo√°n b·ªánh", "üîç Ph√¢n c·ª•m", "üí¨ Chatbox"])
# Tab 1: Xem d·ªØ li·ªáu
with tab1:
    st.header("Xem D·ªØ Li·ªáu")
    st.subheader("Ph√¢n B·ªë C√°c B·ªánh")
    disease_counts = df['B·ªánh hi·ªán t·∫°i'].value_counts().reset_index()
    disease_counts.columns = ["B·ªánh", "S·ªë l∆∞·ª£ng"]
    st.dataframe(disease_counts, use_container_width=True)
    fig = px.bar(disease_counts, x="B·ªánh", y="S·ªë l∆∞·ª£ng", 
                 text="S·ªë l∆∞·ª£ng", 
                 title="Ph√¢n B·ªë C√°c B·ªánh Trong D·ªØ Li·ªáu",
                 color="B·ªánh",
                 height=400)
    fig.update_traces(texttemplate='%{text}', textposition='auto')
    st.plotly_chart(fig, use_container_width=True)

    # Ph√¢n t√≠ch t∆∞∆°ng quan
    correlation_data = df[feature_columns + ['B·ªánh hi·ªán t·∫°i']].copy()
    correlation_data = pd.get_dummies(correlation_data, columns=['B·ªánh hi·ªán t·∫°i'])
    disease_cols = [col for col in correlation_data.columns if col.startswith('B·ªánh hi·ªán t·∫°i_')]
    correlation_results = {}
    for feature in feature_columns:
        correlations = {}
        for disease_col in disease_cols:
            disease_name = le_disease.inverse_transform([int(disease_col.split('_')[-1])])[0]
            corr = correlation_data[feature].corr(correlation_data[disease_col], method='pearson')
            if not np.isnan(corr) and abs(corr) > 0.1:
                correlations[disease_name] = corr
        if correlations:
            correlation_results[feature] = correlations

    # L∆∞u k·∫øt qu·∫£ t∆∞∆°ng quan v√†o session_state
    st.session_state.correlation_results = correlation_results

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ t∆∞∆°ng quan
    for feature, correlations in correlation_results.items():
        st.write(f"**{feature}**")
        for disease, corr in correlations.items():
            st.write(f"- {disease}: {corr:.3f}")

    st.subheader("D·ªØ li·ªáu b·ªánh")
    rows_per_page = st.selectbox("S·ªë d√≤ng m·ªói trang", options=[10, 20, 50, 100], index=0)
    total_rows = len(df)
    total_pages = (total_rows // rows_per_page) + (1 if total_rows % rows_per_page else 0)
    page = st.number_input("Trang", min_value=1, max_value=total_pages, value=1, step=1)
    start_idx = (page - 1) * rows_per_page
    end_idx = start_idx + rows_per_page
    page_data = df.iloc[start_idx:end_idx]
    st.dataframe(page_data, height=300, use_container_width=True)
    st.markdown(f"ƒêang hi·ªÉn th·ªã trang {page}/{total_pages} ({start_idx + 1} - {min(end_idx, total_rows)} tr√™n {total_rows} d√≤ng)")

    st.subheader("D·ªØ li·ªáu b·ªánh vi·ªán")
    st.dataframe(hospital_df, height=300, use_container_width=True)

# Tab 2: D·ª± ƒëo√°n m√¥ h√¨nh
with tab2:
    # T·∫°o th∆∞ m·ª•c l∆∞u m√¥ h√¨nh
    model_folder = "saved_models"
    os.makedirs(model_folder, exist_ok=True)

    # ƒê∆∞·ªùng d·∫´n file
    rf_path = os.path.join(model_folder, "random_forest.pkl")
    dt_path = os.path.join(model_folder, "decision_tree.pkl")

    st.header("D·ª± ƒëo√°n m√¥ h√¨nh")

    # D√πng df_no_dup (ƒë√£ lo·∫°i b·ªè m·∫´u tr√πng)
    X = df_no_dup[feature_columns]
    y = df_no_dup['B·ªánh hi·ªán t·∫°i']

    # Chia d·ªØ li·ªáu v·ªõi stratify ƒë·ªÉ ph√¢n ph·ªëi nh√£n ƒë·ªÅu
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    import numpy as np

    # In th√¥ng tin c∆° b·∫£n
    st.write(f"T·ªïng s·ªë m·∫´u d·ªØ li·ªáu: {len(df_no_dup)}")
    st.write(f"S·ªë m·∫´u train: {len(X_train)}")
    st.write(f"S·ªë m·∫´u test: {len(X_test)}")

    with st.expander("Ph√¢n ph·ªëi nh√£n train"):
        st.dataframe(y_train.value_counts().rename_axis('B·ªánh hi·ªán t·∫°i').reset_index(name='count'))

    with st.expander("Ph√¢n ph·ªëi nh√£n test"):
        st.dataframe(y_test.value_counts().rename_axis('B·ªánh hi·ªán t·∫°i').reset_index(name='count'))

    # Ki·ªÉm tra s·ªë m·∫´u tr√πng train-test
    def count_duplicates(X_train, X_test):
        train_np = X_train.to_numpy()
        duplicate_count = 0
        for i in range(len(X_test)):
            sample = X_test.iloc[i].to_numpy()
            if np.any(np.all(train_np == sample, axis=1)):
                duplicate_count += 1
        return duplicate_count

    st.write(f"S·ªë m·∫´u tr√πng train-test: {count_duplicates(X_train, X_test)}")

    # Hu·∫•n luy·ªán 2 m√¥ h√¨nh
    models = {
        "Decision Tree": DecisionTreeClassifier(random_state=42, class_weight='balanced'),
        "Random Forest": RandomForestClassifier(random_state=42, n_estimators=300, class_weight='balanced'),
    }
# ------------------ T√çCH H·ª¢P L∆ØU / LOAD M√î H√åNH ------------------ #
    model_folder = "saved_models"
    os.makedirs(model_folder, exist_ok=True)
    rf_path = os.path.join(model_folder, "random_forest.pkl")
    dt_path = os.path.join(model_folder, "decision_tree.pkl")

    # N·∫øu m√¥ h√¨nh ƒë√£ t·ªìn t·∫°i ‚Üí load
    rf_model = joblib.load(rf_path) if os.path.exists(rf_path) else None
    dt_model = joblib.load(dt_path) if os.path.exists(dt_path) else None

    model_results = {}

    if rf_model is None or dt_model is None:
        # Train m·ªõi n·∫øu ch∆∞a c√≥
        models = {
            "Decision Tree": DecisionTreeClassifier(random_state=42, class_weight='balanced'),
            "Random Forest": RandomForestClassifier(random_state=42, n_estimators=300, class_weight='balanced'),
        }
        for name, model in models.items():
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
            model_results[name] = {
                "model": model,
                "accuracy": accuracy,
                "report": report
            }
            # L∆∞u l·∫°i m√¥ h√¨nh
            if name == "Random Forest":
                joblib.dump(model, rf_path)
            elif name == "Decision Tree":
                joblib.dump(model, dt_path)
    else:
        # N·∫øu ƒë√£ c√≥ m√¥ h√¨nh ‚Üí ƒë√°nh gi√° l·∫°i
        for name, model in zip(["Decision Tree", "Random Forest"], [dt_model, rf_model]):
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
            model_results[name] = {
                "model": model,
                "accuracy": accuracy,
                "report": report
            }

    # L∆∞u v√†o session_state
    st.session_state.model_results = model_results
# --------------------------------------------------------------- #


    # Hi·ªÉn th·ªã ƒë·ªô ch√≠nh x√°c
    accuracy_df = pd.DataFrame({
        "M√¥ H√¨nh": list(model_results.keys()),
        "ƒê·ªô Ch√≠nh X√°c": [result["accuracy"] for result in model_results.values()]
    })
    st.subheader("T·ªïng H·ª£p ƒê·ªô Ch√≠nh X√°c")
    st.dataframe(accuracy_df, use_container_width=True)

    fig = px.bar(accuracy_df, x="M√¥ H√¨nh", y="ƒê·ªô Ch√≠nh X√°c", 
                 text="ƒê·ªô Ch√≠nh X√°c", 
                 title="So S√°nh ƒê·ªô Ch√≠nh X√°c C·ªßa C√°c M√¥ H√¨nh",
                 color="M√¥ H√¨nh",
                 height=400)
    fig.update_traces(texttemplate='%{text:.4f}', textposition='auto')
    st.plotly_chart(fig, use_container_width=True)

    # Hi·ªÉn th·ªã b√°o c√°o ph√¢n lo·∫°i
    st.subheader("Chi Ti·∫øt B√°o C√°o Ph√¢n Lo·∫°i")
    cols = st.columns(2)
    for idx, (name, result) in enumerate(model_results.items()):
        with cols[idx]:
            with st.expander(f"B√°o C√°o Ph√¢n Lo·∫°i: {name}"):
                report_df = pd.DataFrame({
                    "L·ªõp": [str(k) for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']],
                    "Precision": [result["report"][k]["precision"] for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']],
                    "Recall": [result["report"][k]["recall"] for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']],
                    "F1-Score": [result["report"][k]["f1-score"] for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']],
                    "Support": [result["report"][k]["support"] for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]
                })
                st.dataframe(report_df, use_container_width=True)
                st.write(f"**ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ**: {result['accuracy']:.4f}")


    st.subheader("üîç D·ª± ƒêo√°n B·ªánh T·ª´ Tri·ªáu Ch·ª©ng")
    st.markdown("Nh·∫≠p th√¥ng tin ƒë·ªÉ d·ª± ƒëo√°n b·ªánh.")
    with st.form("symptom_form"):
        age = st.number_input("Tu·ªïi", min_value=0, max_value=120, value=30, key="age")
        gender = st.selectbox("Gi·ªõi t√≠nh", options=["Nam", "N·ªØ"], key="gender")
        region = st.selectbox("Khu v·ª±c", options=["Mi·ªÅn B·∫Øc", "Mi·ªÅn Trung", "Mi·ªÅn Nam"], key="region")

        st.markdown("**Ch·ªçn Tri·ªáu Ch·ª©ng**")
        if st.session_state.get("reset_symptom_form", False):
            for symptom in symptom_columns:
                key = f"symptom_{symptom}"
                if key in st.session_state:
                    del st.session_state[key]
            st.session_state["reset_symptom_form"] = False
            st.rerun()

        # üßæ Render checkbox v√† form
        cols = st.columns(3)
        symptoms = {}
        for idx, symptom in enumerate(symptom_columns):
            col_idx = idx % 3
            with cols[col_idx]:
                symptoms[symptom] = st.checkbox(symptom, key=f"symptom_{symptom}")

        col1, col2 = st.columns([1, 1])
        with col1:
            submitted = st.form_submit_button("D·ª± ƒëo√°n")
        with col2:
            reset = st.form_submit_button("Reset Tri·ªáu Ch·ª©ng")

        # üîò N·∫øu nh·∫•n Reset, ƒë·∫∑t c·ªù v√† rerun
        if reset:
            st.session_state["reset_symptom_form"] = True
            st.rerun()

        if submitted:
            if not st.session_state.model_results or not st.session_state.le_disease or not st.session_state.le_gender:
                st.error("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc!")
                st.stop()
            try:
                age_val = st.session_state["age"]
                gender_val = st.session_state["gender"]
                region_val = st.session_state["region"]
                symptoms_selected = {col: st.session_state.get(f"symptom_{col}", False) for col in symptom_columns}

                input_data = pd.DataFrame(columns=st.session_state.feature_columns)
                input_data.loc[0, 'Tu·ªïi'] = age
                gender_normalized = gender.strip().capitalize()
                input_data.loc[0, 'Gi·ªõi t√≠nh'] = st.session_state.le_gender.transform([gender_normalized])[0]
                for col in symptom_columns:
                    input_data.loc[0, col] = 1 if symptoms[col] else 0
                input_data = input_data.fillna(0).infer_objects(copy=False).astype(int)

                num_symptoms = sum(1 for col, val in symptoms.items() if val)
                if num_symptoms < 2:
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t 2 tri·ªáu ch·ª©ng ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c h∆°n.")
                    st.stop()

                light_diseases = ["C√∫m", "Vi√™m h·ªçng", "Vi√™m amidan"]
                severe_symptoms = ["Kh√≥ th·ªü", "ƒêau ng·ª±c", "M·∫•t v·ªã gi√°c", "M·∫•t kh·ª©u gi√°c"]
                has_severe_symptom = any(symptom in symptoms and symptoms[symptom] for symptom in severe_symptoms)

                st.write("#### K·∫øt Qu·∫£ D·ª± ƒêo√°n")
                all_diseases = []
                model_predictions = {}
                top_disease_for_hospital = None
                for name, result in st.session_state.model_results.items():
                    model = result["model"]
                    model_predictions[name] = []
                    st.write(f"**{name}**:")
                    if hasattr(model, "predict_proba"):
                        probs = model.predict_proba(input_data)[0]
                        # ƒêi·ªÅu ch·ªânh x√°c su·∫•t d·ª±a tr√™n t∆∞∆°ng quan
                        adjusted_probs = probs.copy()
                        correlation_adjustments = []
                        if 'correlation_results' in st.session_state:
                            for feature in feature_columns:
                                    if feature in st.session_state.correlation_results:
                                        for disease, corr in st.session_state.correlation_results[feature].items():
                                            if disease in st.session_state.le_disease.classes_:
                                                disease_idx = np.where(st.session_state.le_disease.classes_ == disease)[0]
                                                if len(disease_idx) > 0:
                                                    old_prob = adjusted_probs[disease_idx[0]]
                                                    new_prob = old_prob + (old_prob * corr * 0.5)
                                                    adjusted_probs[disease_idx[0]] = new_prob
                                                    correlation_adjustments.append({
                                                        "Feature": feature,
                                                        "B·ªánh": disease,
                                                        "T∆∞∆°ng quan": f"{corr:.3f}",
                                                        "TƒÉng x√°c su·∫•t": f"{disease}: t·ª´ {old_prob:.2%} l√™n {new_prob:.2%}"
                                                    })
                        adjusted_probs = adjusted_probs / adjusted_probs.sum()

                        # ƒêi·ªÅu ch·ªânh x√°c su·∫•t n·∫øu s·ªë l∆∞·ª£ng tri·ªáu ch·ª©ng <= 4 v√† kh√¥ng c√≥ tri·ªáu ch·ª©ng ƒë·∫∑c tr∆∞ng
                        if num_symptoms <= 4 and not has_severe_symptom:
                            for idx, disease in enumerate(st.session_state.le_disease.classes_):
                                if disease in light_diseases:
                                    adjusted_probs[idx] *= 3.0
                            adjusted_probs = adjusted_probs / adjusted_probs.sum()

                        top_indices = np.argsort(adjusted_probs)[-3:][::-1]
                        model_diseases = [(st.session_state.le_disease.inverse_transform([i])[0], adjusted_probs[i]) for i in top_indices]
                        for disease, prob in model_diseases:
                            st.write(f"- {disease}: {prob:.2%}")
                            model_predictions[name].append((disease, prob))
                        st.success(f"‚úÖ D·ª± ƒëo√°n ch√≠nh: **{model_diseases[0][0]}** v·ªõi x√°c su·∫•t {model_diseases[0][1]:.2%}")
                        all_diseases.extend([(disease, prob, name) for disease, prob in model_diseases])
                        if name == "Random Forest":
                            top_disease_for_hospital = model_diseases[0][0]
                    else:
                        prediction = model.predict(input_data)
                        predicted_disease = st.session_state.le_disease.inverse_transform(prediction)[0]
                        st.write(f"{predicted_disease} (m√¥ h√¨nh kh√¥ng h·ªó tr·ª£ x√°c su·∫•t)")
                        model_predictions[name].append((predicted_disease, 0.0))
                        all_diseases.append((predicted_disease, 0.0, name))

                rf_diseases = sorted(model_predictions["Random Forest"], key=lambda x: x[1], reverse=True)[:2]
                final_diseases = [(disease, prob, "Random Forest") for disease, prob in rf_diseases]
                rf_diseases_set = set(disease for disease, _, _ in final_diseases)

                # ‚ö†Ô∏è L·ªçc c√°c b·ªánh t·ª´ Decision Tree c√≥ x√°c su·∫•t > 0
                other_diseases = [
                    (disease, prob, model)
                    for disease, prob, model in all_diseases
                    if model == "Decision Tree" and disease not in rf_diseases_set and prob > 0.001
                ]

                if other_diseases:
                    other_diseases = sorted(other_diseases, key=lambda x: x[1], reverse=True)
                    final_diseases.append(other_diseases[0])
                else:
                    # N·∫øu RF c√≤n b·ªánh th·ª© 3 v√† ch∆∞a c√≥ trong final_diseases th√¨ th√™m v√†o
                    sorted_rf = sorted(model_predictions["Random Forest"], key=lambda x: x[1], reverse=True)
                    if len(sorted_rf) > 2:
                        third_rf_disease = sorted_rf[2]
                        if third_rf_disease[0] not in rf_diseases_set:
                            final_diseases.append((third_rf_disease[0], third_rf_disease[1], "Random Forest"))

                # Ch·ªçn l·∫°i top 3 theo x√°c su·∫•t
                final_diseases = sorted(final_diseases, key=lambda x: x[1], reverse=True)[:3]

                colors = ["#28a745", "#fd7e14", "#6f42c1"]

                st.markdown("### ü©∫ **K·∫øt Qu·∫£ T∆∞ V·∫•n C√° Nh√¢n H√≥a**")
                st.markdown(f"""
                **Th√¥ng tin ng∆∞·ªùi d√πng:**
                - Tu·ªïi: {age}
                - Gi·ªõi t√≠nh: {gender}
                - Khu v·ª±c: {region}
                - Tri·ªáu ch·ª©ng: {', '.join([col for col, val in symptoms.items() if val]) or 'Kh√¥ng c√≥'}

                **M√¥ h√¨nh d·ª± ƒëo√°n:**
                K·∫øt qu·∫£ d·ª± ƒëo√°n ch√≠nh l√†:
                """)
                for idx, (disease, prob, model) in enumerate(final_diseases):
                    st.markdown(f"- <span style='color:{colors[idx]}'>{disease}</span>", unsafe_allow_html=True)
                st.markdown("- D·ª±a tr√™n t·ªï h·ª£p c√°c tri·ªáu ch·ª©ng v√† ti·ªÅn s·ª≠ b·ªánh li√™n quan")

                st.markdown("**G·ª£i √Ω h√†nh ƒë·ªông:**")
                for disease, prob, model in final_diseases:
                    hospitals, severity, action = suggest_hospitals_and_actions(disease, hospital_df, action_dict, region)
                    note = ""
                    if prob < 0.1:
                        note = "<p><em>‚ö†Ô∏è L∆∞u √Ω: B·ªánh n√†y ƒë∆∞·ª£c m√¥ h√¨nh g·ª£i √Ω nh∆∞ng c√≥ x√°c su·∫•t r·∫•t th·∫•p.</em></p>"
                    with st.container():
                        st.markdown(f"""
                        <div class="suggestion-box">
                            <h4>B·ªánh: {disease} ({prob:.2%})</h4>
                            <p><strong>M·ª©c ƒë·ªô nghi√™m tr·ªçng:</strong> {severity}</p>
                            <p><strong>H√†nh ƒë·ªông:</strong> {action}</p>
                            <p><strong>B·ªánh vi·ªán g·ª£i √Ω:</strong> {', '.join(hospitals)}</p>
                        </div>
                        """, unsafe_allow_html=True)
                st.info("‚ö†Ô∏è ƒê√¢y ch·ªâ l√† g·ª£i √Ω t·ª´ m√¥ h√¨nh h·ªçc m√°y. H√£y ƒë·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c kh√°m v√† ch·∫©n ƒëo√°n ch√≠nh x√°c.")

            except ValueError as e:
                st.error(f"L·ªói khi d·ª± ƒëo√°n: {str(e)}. Vui l√≤ng ki·ªÉm tra gi√° tr·ªã ƒë·∫ßu v√†o.")
                st.stop()

# Tab 3: Ph√¢n c·ª•m
with tab3:
    st.header("üîç D·ª± ƒêo√°n B·ªánh B·∫±ng Ph√¢n C·ª•m v√† Lu·∫≠t K·∫øt H·ª£p")

    X = df[feature_columns]
    y = df['B·ªánh hi·ªán t·∫°i']

    try:
        smote = SMOTE(random_state=42)
        X_resampled, y_resampled = smote.fit_resample(X, y)
        df_resampled = pd.DataFrame(X_resampled, columns=feature_columns)
        df_resampled['B·ªánh hi·ªán t·∫°i'] = y_resampled
    except ValueError:
        X_resampled, y_resampled = X, y
        df_resampled = df.copy()

    num_clusters = st.slider("S·ªë l∆∞·ª£ng c·ª•m", min_value=3, max_value=15, value=7)

    st.subheader("‚öôÔ∏è C·∫•u H√¨nh Apriori")
    min_support = st.slider("Min Support", min_value=0.01, max_value=0.5, value=0.05, step=0.01, format="%.2f")
    min_confidence = st.slider("Min Confidence", min_value=0.1, max_value=1.0, value=0.6, step=0.1, format="%.1f")
    min_lift = st.slider("Min Lift", min_value=1.0, max_value=10.0, value=1.0, step=0.1, format="%.1f")

    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X_resampled)
    df_resampled['C·ª•m'] = cluster_labels
    st.session_state.clusters = cluster_labels

    st.subheader("üìú T√¨m Lu·∫≠t K·∫øt H·ª£p Trong T·ª´ng C·ª•m")
    cluster_rules = {}
    for cluster in range(num_clusters):
        cluster_data = df_resampled[df_resampled['C·ª•m'] == cluster]
        if len(cluster_data) < 2:
            cluster_rules[cluster] = []
            continue

        transactions = []
        for idx, row in cluster_data.iterrows():
            transaction = []
            for col in symptom_columns:
                if row[col] == 1:
                    transaction.append(col)
            disease = st.session_state.le_disease.inverse_transform([row['B·ªánh hi·ªán t·∫°i']])[0]
            transaction.append(f"B·ªánh_{disease}")
            transactions.append(transaction)

        if not transactions:
            cluster_rules[cluster] = []
            continue
        transaction_binary = pd.DataFrame(0, index=range(len(transactions)), columns=np.unique(np.concatenate(transactions)))
        for idx, transaction in enumerate(transactions):
            for item in transaction:
                transaction_binary.loc[idx, item] = 1

        frequent_itemsets_df = apriori(transaction_binary, min_support=min_support, use_colnames=True)
        if frequent_itemsets_df.empty:
            cluster_rules[cluster] = []
            continue

        rules = association_rules(frequent_itemsets_df, metric="confidence", min_threshold=min_confidence)
        rules = rules[rules['lift'] >= min_lift]
        cluster_rules[cluster] = rules

    st.session_state.cluster_rules = cluster_rules

    st.subheader("üìä Th√¥ng Tin V·ªÅ C√°c C·ª•m")
    for cluster in range(num_clusters):
        cluster_data = df_resampled[df_resampled['C·ª•m'] == cluster]
        with st.expander(f"C·ª•m {cluster} ({len(cluster_data)} b·ªánh nh√¢n)"):
            symptom_means = cluster_data[symptom_columns].mean().sort_values(ascending=False)
            top_symptoms = symptom_means.head(2)
            symptom_df = pd.DataFrame({
                "Tri·ªáu ch·ª©ng": top_symptoms.index,
                "T·ª∑ l·ªá": [f"{value:.2%}" for value in top_symptoms.values]
            })
            st.write("**Tri·ªáu ch·ª©ng ph·ªï bi·∫øn nh·∫•t:**")
            st.dataframe(symptom_df, use_container_width=True, hide_index=True)


            disease_counts = cluster_data['B·ªánh hi·ªán t·∫°i'].value_counts().head(2)
            disease_df = pd.DataFrame({
                "B·ªánh": [st.session_state.le_disease.inverse_transform([idx])[0] for idx in disease_counts.index],
                "S·ªë b·ªánh nh√¢n": disease_counts.values,
                "T·ª∑ l·ªá": [f"{count/len(cluster_data):.2%}" for count in disease_counts.values]
            })
            st.write("**B·ªánh ph·ªï bi·∫øn nh·∫•t:**")
            st.dataframe(disease_df, use_container_width=True, hide_index=True)

            rules = cluster_rules.get(cluster, [])
            if not rules.empty:
                st.write("**Lu·∫≠t k·∫øt h·ª£p ph·ªï bi·∫øn nh·∫•t:**")
                rule_display = []
                for idx, row in rules.iterrows():
                    antecedents = list(row['antecedents'])
                    consequents = list(row['consequents'])
                    confidence = row['confidence']
                    lift = row['lift']
                    rule_display.append({
                        "ƒêi·ªÅu ki·ªán": ", ".join(antecedents),
                        "K·∫øt lu·∫≠n": ", ".join(consequents),
                        "ƒê·ªô tin c·∫≠y": f"{confidence:.2%}",
                        "ƒê·ªô n√¢ng": f"{lift:.2f}"
                    })
                st.dataframe(pd.DataFrame(rule_display), use_container_width=True, hide_index=True)
            else:
                st.write("Kh√¥ng t√¨m th·∫•y lu·∫≠t k·∫øt h·ª£p n√†o trong c·ª•m n√†y.")

    st.subheader("üîç D·ª± ƒêo√°n B·ªánh T·ª´ C·ª•m")
    with st.form("cluster_prediction_form"):
        age = st.number_input("Tu·ªïi", min_value=0, max_value=120, value=30, key="cluster_age")
        gender = st.selectbox("Gi·ªõi t√≠nh", options=["Nam", "N·ªØ"], key="cluster_gender")
        region = st.selectbox("Khu v·ª±c", options=["Mi·ªÅn B·∫Øc", "Mi·ªÅn Trung", "Mi·ªÅn Nam"], key="cluster_region")

        st.markdown("**Ch·ªçn Tri·ªáu Ch·ª©ng**")
        if st.session_state.get("reset_cluster_form", False):
            for symptom in symptom_columns:
                key = f"cluster_symptom_{symptom}"
                if key in st.session_state:
                    del st.session_state[key]  # ‚ùóX√≥a kh·ªèi session_state ƒë·ªÉ kh√¥ng l·ªói
            st.session_state["reset_cluster_form"] = False
            st.rerun()
        cols = st.columns(3)
        cluster_symptoms = {}
        for idx, symptom in enumerate(symptom_columns):
            col_idx = idx % 3
            with cols[col_idx]:
                default_value = False if st.session_state.get("reset_cluster_form", False) else st.session_state.get(f"cluster_symptom_{symptom}", False)
                cluster_symptoms[symptom] = st.checkbox(symptom, value=default_value, key=f"cluster_symptom_{symptom}")

        col1, col2 = st.columns([1, 1])
        with col1:
            submitted = st.form_submit_button("üîç D·ª± ƒëo√°n t·ª´ c·ª•m")
        with col2:
           reset = st.form_submit_button("Reset Tri·ªáu Ch·ª©ng")
        if reset:
            st.session_state["reset_cluster_form"] = True
            st.rerun()

        # N·∫øu b·∫•m Reset, c·∫≠p nh·∫≠t session_state tr∆∞·ªõc khi render
        if st.session_state.get("reset_cluster_form", False):
            for symptom in symptom_columns:
                st.session_state[f"cluster_symptom_{symptom}"] = False
            st.session_state["reset_cluster_form"] = False
            st.rerun()


        if st.session_state.get("reset_cluster_form", False):
            st.session_state["reset_cluster_form"] = False

        if submitted:
            # L·∫•y d·ªØ li·ªáu nh·∫≠p v√†o
            age_val = st.session_state["cluster_age"]
            gender_val = st.session_state["cluster_gender"]
            region_val = st.session_state["cluster_region"]
            symptoms_selected = {col: st.session_state.get(f"cluster_symptom_{col}", False) for col in symptom_columns}

            # T·∫°o dataframe input ƒë√∫ng ƒë·ªãnh d·∫°ng
            input_data = pd.DataFrame(columns=feature_columns)
            input_data.loc[0, 'Tu·ªïi'] = age_val
            gender_normalized = gender_val.strip().capitalize()
            input_data.loc[0, 'Gi·ªõi t√≠nh'] = st.session_state.le_gender.transform([gender_normalized])[0]

            for col in symptom_columns:
                input_data.loc[0, col] = 1 if symptoms_selected[col] else 0
            input_data = input_data.fillna(0).astype(int)

            num_symptoms = sum(val for val in symptoms_selected.values())
            if num_symptoms < 3:
                st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t 3 tri·ªáu ch·ª©ng ƒë·ªÉ tƒÉng kh·∫£ nƒÉng t√¨m lu·∫≠t k·∫øt h·ª£p.")
                st.stop()

            # D·ª± ƒëo√°n c·ª•m
            cluster_assignment = kmeans.predict(input_data)[0]
            st.write(f"Tri·ªáu ch·ª©ng ƒë·∫ßu v√†o thu·ªôc **C·ª•m {cluster_assignment}**")

            # L·∫•y d·ªØ li·ªáu c·ªßa c·ª•m d·ª± ƒëo√°n
            cluster_data = df_resampled[df_resampled['C·ª•m'] == cluster_assignment]
            if len(cluster_data) < 2:
                st.warning("‚ö†Ô∏è C·ª•m n√†y c√≥ qu√° √≠t d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c. Vui l√≤ng th·ª≠ v·ªõi s·ªë l∆∞·ª£ng c·ª•m kh√°c.")
                st.stop()

            # Ph√¢n ph·ªëi b·ªánh trong c·ª•m
            disease_counts = cluster_data['B·ªánh hi·ªán t·∫°i'].value_counts()
            st.write("**Ph√¢n b·ªë b·ªánh trong c·ª•m:**")
            disease_distribution = pd.DataFrame({
                "B·ªánh": [st.session_state.le_disease.inverse_transform([idx])[0] for idx in disease_counts.index],
                "S·ªë b·ªánh nh√¢n": disease_counts.values,
                "T·ª∑ l·ªá": [f"{count/len(cluster_data):.2%}" for count in disease_counts.values]
            })
            st.dataframe(disease_distribution, use_container_width=True, hide_index=True)

            # Hu·∫•n luy·ªán logistic regression trong c·ª•m
            X_cluster = cluster_data[feature_columns]
            y_cluster = cluster_data['B·ªánh hi·ªán t·∫°i']
            lr = LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial', class_weight='balanced')
            lr.fit(X_cluster, y_cluster)

            # D·ª± ƒëo√°n x√°c su·∫•t
            probs = lr.predict_proba(input_data)[0]

            # T√¨m lu·∫≠t k·∫øt h·ª£p kh·ªõp v·ªõi tri·ªáu ch·ª©ng
            matched_rules = []
            if st.session_state.cluster_rules and cluster_assignment in st.session_state.cluster_rules:
                rules = st.session_state.cluster_rules[cluster_assignment]
                if not rules.empty:
                    input_items = [col for col, val in symptoms_selected.items() if val]
                    input_set = set(input_items)

                    for idx, row in rules.iterrows():
                        antecedents = set(row['antecedents'])
                        consequents = set(row['consequents'])
                        confidence = row['confidence']
                        matched_items = len(antecedents.intersection(input_set))
                        match_ratio = matched_items / len(antecedents) if len(antecedents) > 0 else 0
                        if match_ratio >= 0.5:
                            for consequent in consequents:
                                if consequent.startswith("B·ªánh_"):
                                    disease = consequent.replace("B·ªánh_", "")
                                    matched_rules.append({
                                        "disease": disease,
                                        "confidence": confidence * match_ratio,
                                        "antecedents": ", ".join(antecedents),
                                        "match_ratio": match_ratio
                                    })

            if matched_rules:
                st.write("**Lu·∫≠t k·∫øt h·ª£p kh·ªõp v·ªõi tri·ªáu ch·ª©ng ƒë·∫ßu v√†o (tham kh·∫£o):**")
                rule_display = []
                for rule in matched_rules:
                    rule_display.append({
                        "ƒêi·ªÅu ki·ªán": rule['antecedents'],
                        "K·∫øt lu·∫≠n": rule['disease'],
                        "ƒê·ªô tin c·∫≠y": f"{rule['confidence']:.2%}",
                        "T·ª∑ l·ªá kh·ªõp": f"{rule['match_ratio']:.0%}"
                    })
                st.dataframe(pd.DataFrame(rule_display), use_container_width=True, hide_index=True)

            # Chu·∫©n h√≥a x√°c su·∫•t tr√°nh 0
            adjusted_probs = probs + 1e-3
            adjusted_probs = adjusted_probs / adjusted_probs.sum()

            # Hi·ªÉn th·ªã 3 b·ªánh c√≥ x√°c su·∫•t cao nh·∫•t
            top_indices = np.argsort(adjusted_probs)[-3:][::-1]
            top_diseases = [(st.session_state.le_disease.inverse_transform([i])[0], adjusted_probs[i]) for i in top_indices]

            st.write("### Top 3 b·ªánh d·ª± ƒëo√°n:")
            for disease, prob in top_diseases:
                st.write(f"- {disease}")
            st.success(f"‚úÖ D·ª± ƒëo√°n ch√≠nh: {top_diseases[0][0]}")

            st.write("**Tri·ªáu ch·ª©ng quan tr·ªçng nh·∫•t ·∫£nh h∆∞·ªüng ƒë·∫øn d·ª± ƒëo√°n:**")
            feature_importance = pd.Series(lr.coef_[lr.classes_ == top_indices[0]][0], index=feature_columns)
            top_features = feature_importance.sort_values(ascending=False).head(3)
            for feature, coef in top_features.items():
                st.write(f"- {feature}: h·ªá s·ªë {coef:.3f}")

            st.markdown("**G·ª£i √Ω b·ªánh vi·ªán v√† h√†nh ƒë·ªông cho c√°c b·ªánh d·ª± ƒëo√°n:**")
            for idx, (disease, prob) in enumerate(top_diseases):
                hospitals, severity, action = suggest_hospitals_and_actions(disease, hospital_df, action_dict, region)
                note = ""
                if prob < 0.1:
                    note = "<p><em>‚ö†Ô∏è L∆∞u √Ω: B·ªánh n√†y ƒë∆∞·ª£c m√¥ h√¨nh g·ª£i √Ω nh∆∞ng c√≥ x√°c su·∫•t r·∫•t th·∫•p.</em></p>"
                with st.container():
                    st.markdown(f"""
                    <div class="suggestion-box">
                        <h4>B·ªánh: {disease} ({prob:.2%})</h4>
                        <p><strong>M·ª©c ƒë·ªô nghi√™m tr·ªçng:</strong> {severity}</p>
                        <p><strong>H√†nh ƒë·ªông:</strong> {action}</p>
                        <p><strong>B·ªánh vi·ªán g·ª£i √Ω:</strong> {', '.join(hospitals)}</p>
                    </div>
                    """, unsafe_allow_html=True)
            st.info("‚ö†Ô∏è ƒê√¢y ch·ªâ l√† g·ª£i √Ω t·ª´ ph∆∞∆°ng ph√°p ph√¢n c·ª•m v√† lu·∫≠t k·∫øt h·ª£p. H√£y ƒë·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c kh√°m v√† ch·∫©n ƒëo√°n ch√≠nh x√°c.")
# Tab 4: Chatbox
with tab4:
    # N·∫øu b·∫•m Reset, c·∫≠p nh·∫≠t session_state tr∆∞·ªõc khi render
    if st.session_state.get("reset_cluster_form", False):
        for symptom in symptom_columns:
            st.session_state[f"cluster_symptom_{symptom}"] = False
        st.session_state["reset_cluster_form"] = False
        st.rerun()

    st.header("üí¨ T∆∞ V·∫•n S·ª©c Kh·ªèe T·ª± ƒê·ªông")
    st.markdown("H√£y nh·∫≠p c√¢u h·ªèi m√¥ t·∫£ tri·ªáu ch·ª©ng, v√≠ d·ª•: `T√¥i b·ªã ho v√† s·ªët 2 ng√†y nay.`")

    region = st.selectbox("üåç Ch·ªçn khu v·ª±c b·∫°n s·ªëng", ["Mi·ªÅn B·∫Øc", "Mi·ªÅn Trung", "Mi·ªÅn Nam"], key="chat_region")

    age = st.number_input("üéÇ Tu·ªïi c·ªßa b·∫°n", min_value=0, max_value=120, value=30, step=1, key="chat_age")
    gender = st.radio("üë§ Gi·ªõi t√≠nh c·ªßa b·∫°n", ["Nam", "N·ªØ"], key="chat_gender")

    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []

    user_input = st.text_input("üßë B·∫°n:", placeholder="T√¥i b·ªã ƒëau h·ªçng v√† kh√≥ th·ªü...")

    def normalize_text(text):
        import unicodedata
        return ''.join(c for c in unicodedata.normalize('NFD', text.lower()) if unicodedata.category(c) != 'Mn')

    def generate_chatbot_response(message, age, gender, region):
        if not st.session_state.model_results or "Random Forest" not in st.session_state.model_results:
            return "‚ö†Ô∏è M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng v√†o tab 'D·ª± ƒëo√°n b·ªánh' ƒë·ªÉ hu·∫•n luy·ªán tr∆∞·ªõc."

        message = normalize_text(message)
        found_symptoms = [symptom for symptom in symptom_columns if normalize_text(symptom) in message]

        if not found_symptoms:
            return "ü§ñ T√¥i ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c tri·ªáu ch·ª©ng n√†o r√µ r√†ng. B·∫°n c√≥ th·ªÉ m√¥ t·∫£ c·ª• th·ªÉ h∆°n kh√¥ng?"

        input_data = {col: 0 for col in feature_columns}
        for symptom in found_symptoms:
            input_data[symptom] = 1
        input_data["Tu·ªïi"] = age
        input_data["Gi·ªõi t√≠nh"] = st.session_state.le_gender.transform([gender])[0]

        input_df = pd.DataFrame([input_data])

        model = st.session_state.model_results["Random Forest"]["model"]
        probs = model.predict_proba(input_df)[0]
        top_indices = probs.argsort()[-2:][::-1]  # L·∫•y 2 b·ªánh c√≥ x√°c su·∫•t cao nh·∫•t
        top_diseases = [(st.session_state.le_disease.inverse_transform([i])[0], probs[i]) for i in top_indices]

        result_lines = ["ü§ñ **CH·∫®N ƒêO√ÅN C√ì TH·ªÇ:**"]
        for disease, confidence in top_diseases:
            severity = action_dict.get(disease, {}).get("severity", "Ch∆∞a r√µ")
            action = action_dict.get(disease, {}).get("action", "Vui l√≤ng ƒë·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n c·ª• th·ªÉ.")

            matches = hospital_df[(hospital_df["B·ªánh"] == disease) & (hospital_df["Khu v·ª±c"] == region)]
            hospitals = matches["B·ªánh vi·ªán"].dropna().tolist()
            if not hospitals:
                hospitals = ["Kh√¥ng c√≥ b·ªánh vi·ªán g·ª£i √Ω trong khu v·ª±c. H√£y ƒë·∫øn c∆° s·ªü y t·∫ø g·∫ßn nh·∫•t."]

            result_lines.append(
                f"""ü©∫ **{disease.upper()}** 
    ‚ù§Ô∏è **M·ª©c ƒë·ªô nghi√™m tr·ªçng:** {severity}  
    üìå **H∆∞·ªõng x·ª≠ l√Ω:** {action}  
    üè• **G·ª£i √Ω b·ªánh vi·ªán ({region}):** {', '.join(hospitals)}"""
            )

        return "\n\n".join(result_lines)


    if st.button("üì® G·ª≠i"):
        if user_input.strip() != "":
            reply = generate_chatbot_response(user_input, age, gender, region)
            st.session_state.chat_history.append(("üßë B·∫°n", user_input))
            st.session_state.chat_history.append(("ü§ñ H·ªá th·ªëng", reply))
            user_input = ""

    if st.session_state.chat_history:
        st.markdown("---")
        st.subheader("üìú L·ªãch s·ª≠ tr√≤ chuy·ªán")
        for sender, msg in st.session_state.chat_history[-6:]:  # Hi·ªÉn th·ªã 6 d√≤ng g·∫ßn nh·∫•t
            if sender == "üßë B·∫°n":
                st.markdown(f"**{sender}:** {msg}")
            else:
                st.markdown(
                    f"<div style='background-color:#f1f1f1;padding:10px;border-radius:8px;margin-bottom:8px'>"
                    f"<strong>{sender}:</strong><br>{msg}</div>",
                    unsafe_allow_html=True
                )
