import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTE
from mlxtend.frequent_patterns import apriori, association_rules

# T·∫Øt c·∫£nh b√°o li√™n quan ƒë·∫øn downcasting
pd.set_option('future.no_silent_downcasting', True)

# C·∫•u h√¨nh trang
st.set_page_config(page_title="·ª®ng D·ª•ng D·ª± ƒêo√°n B·ªánh", layout="wide")

# CSS ƒë·ªÉ ƒë√≥ng khung ph·∫ßn "G·ª£i √Ω h√†nh ƒë·ªông" v√† b·∫£ng lu·∫≠t k·∫øt h·ª£p
st.markdown("""
<style>
.suggestion-box {
    border: 2px solid #28a745;
    border-radius: 10px;
    padding: 15px;
    background-color: #f8fff8;
    margin-bottom: 20px;
}
.suggestion-box h4 {
    color: #28a745;
    margin-bottom: 10px;
}
.suggestion-box p {
    margin: 5px 0;
    font-size: 16px;
}
.stDataFrame table {
    width: 100%;
    border-collapse: collapse;
}
.stDataFrame th, .stDataFrame td {
    padding: 8px;
    text-align: center;
    border: 1px solid #ddd;
}
.stDataFrame th {
    background-color: #f2f2f2;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

# Ti√™u ƒë·ªÅ v√† m√¥ t·∫£
st.title("ü©∫ D·ª± ƒêo√°n B·ªánh T·ª´ Tri·ªáu Ch·ª©ng")
st.markdown("""
·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng m√¥ h√¨nh m√°y h·ªçc v√† ph√¢n c·ª•m ƒë·ªÉ d·ª± ƒëo√°n b·ªánh d·ª±a tr√™n tri·ªáu ch·ª©ng v√† b·ªánh ti·ªÅn s·ª≠.
""")

# H√†m t√¨m b·ªánh g·∫ßn gi·ªëng nh·∫•t
def find_closest_disease(disease, reference_list):
    disease = disease.lower()
    for ref_disease in reference_list:
        ref_disease_lower = ref_disease.lower()
        if disease in ref_disease_lower or ref_disease_lower in disease:
            return ref_disease
    return None

# H√†m g·ª£i √Ω b·ªánh vi·ªán v√† h√†nh ƒë·ªông
def suggest_hospitals_and_actions(disease, hospital_df, action_dict, region):
    matches = hospital_df[(hospital_df["B·ªánh"] == disease) & (hospital_df["Khu v·ª±c"] == region)]
    if matches.empty:
        closest_disease = find_closest_disease(disease, hospital_df["B·ªánh"].unique())
        if closest_disease:
            matches = hospital_df[(hospital_df["B·ªánh"] == closest_disease) & (hospital_df["Khu v·ª±c"] == region)]
            disease = closest_disease
    hospitals = matches["B·ªánh vi·ªán"].dropna().tolist()
    
    if not hospitals:
        hospitals = ["Kh√¥ng c√≥ b·ªánh vi·ªán g·ª£i √Ω trong khu v·ª±c n√†y, vui l√≤ng ƒë·∫øn c∆° s·ªü y t·∫ø g·∫ßn nh·∫•t."]
    
    if disease in action_dict:
        action_info = action_dict[disease]
    else:
        closest_disease = find_closest_disease(disease, action_dict.keys())
        if closest_disease:
            action_info = action_dict[closest_disease]
        else:
            action_info = {"severity": "Ch∆∞a c√≥ th√¥ng tin", "action": "C·∫ßn tham kh·∫£o √Ω ki·∫øn b√°c sƒ© ƒë·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô nghi√™m tr·ªçng."}
    
    return hospitals, action_info["severity"], action_info["action"]

# Kh·ªüi t·∫°o session_state
if 'le_disease' not in st.session_state:
    st.session_state.le_disease = None
if 'model_results' not in st.session_state:
    st.session_state.model_results = None
if 'symptom_columns' not in st.session_state:
    st.session_state.symptom_columns = None
if 'pre_existing_conditions' not in st.session_state:
    st.session_state.pre_existing_conditions = None
if 'feature_columns' not in st.session_state:
    st.session_state.feature_columns = None
if 'le_gender' not in st.session_state:
    st.session_state.le_gender = None
if 'reset_symptom_form' not in st.session_state:
    st.session_state.reset_symptom_form = False
if 'reset_cluster_form' not in st.session_state:
    st.session_state.reset_cluster_form = False
if 'clusters' not in st.session_state:
    st.session_state.clusters = None
if 'cluster_diseases' not in st.session_state:
    st.session_state.cluster_diseases = None
if 'cluster_rules' not in st.session_state:
    st.session_state.cluster_rules = None

# Hard-code g·ª£i √Ω h√†nh ƒë·ªông v√† m·ª©c ƒë·ªô nghi√™m tr·ªçng
action_dict = {
    "Covid-19": {"severity": "Cao", "action": "C√°ch ly t·∫°i nh√†, li√™n h·ªá y t·∫ø ngay n·∫øu kh√≥ th·ªü."},
    "C√∫m": {"severity": "Trung b√¨nh", "action": "Ngh·ªâ ng∆°i, u·ªëng nhi·ªÅu n∆∞·ªõc, d√πng thu·ªëc h·∫° s·ªët n·∫øu c·∫ßn."},
    "Suy nh∆∞·ª£c c∆° th·ªÉ": {"severity": "Th·∫•p", "action": "TƒÉng c∆∞·ªùng dinh d∆∞·ª°ng, ngh·ªâ ng∆°i h·ª£p l√Ω."},
    "Vi√™m ph·ªïi": {"severity": "Cao", "action": "ƒêi kh√°m ngay t·∫°i b·ªánh vi·ªán, tr√°nh t·ª± ƒëi·ªÅu tr·ªã."},
    "Vi√™m h·ªçng": {"severity": "Th·∫•p", "action": "S√∫c mi·ªáng n∆∞·ªõc mu·ªëi, ngh·ªâ ng∆°i, u·ªëng nhi·ªÅu n∆∞·ªõc."},
    "ƒêau d·∫° d√†y": {"severity": "Trung b√¨nh", "action": "ƒÇn nh·∫π, tr√°nh ƒë·ªì chua cay, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu ƒëau k√©o d√†i."},
    "S·ªët xu·∫•t huy·∫øt": {"severity": "Cao", "action": "Theo d√µi s√°t sao, ƒëi kh√°m ngay n·∫øu c√≥ d·∫•u hi·ªáu xu·∫•t huy·∫øt."},
    "Ti·ªÉu ƒë∆∞·ªùng": {"severity": "Trung b√¨nh", "action": "Ki·ªÉm tra ƒë∆∞·ªùng huy·∫øt th∆∞·ªùng xuy√™n, tu√¢n th·ªß ch·∫ø ƒë·ªô ƒÉn u·ªëng."},
    "Cao huy·∫øt √°p": {"severity": "Trung b√¨nh", "action": "Theo d√µi huy·∫øt √°p, h·∫°n ch·∫ø mu·ªëi, tham kh·∫£o √Ω ki·∫øn b√°c sƒ©."},
    "Vi√™m xoang": {"severity": "Trung b√¨nh", "action": "Gi·ªØ m≈©i s·∫°ch, tr√°nh kh√≥i b·ª•i, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu k√©o d√†i."},
    "Hen suy·ªÖn": {"severity": "Cao", "action": "S·ª≠ d·ª•ng thu·ªëc c·∫Øt c∆°n n·∫øu c√≥, ƒëi kh√°m ngay n·∫øu kh√≥ th·ªü n·∫∑ng."},
    "Vi√™m amidan": {"severity": "Th·∫•p", "action": "S√∫c mi·ªáng n∆∞·ªõc mu·ªëi, ngh·ªâ ng∆°i, d√πng thu·ªëc kh√°ng sinh n·∫øu b√°c sƒ© k√™ ƒë∆°n."},
    "Tr·∫ßm c·∫£m": {"severity": "Trung b√¨nh", "action": "Tham kh·∫£o √Ω ki·∫øn b√°c sƒ© t√¢m l√Ω, duy tr√¨ l·ªëi s·ªëng l√†nh m·∫°nh."},
    "Vi√™m ph·∫ø qu·∫£n": {"severity": "Trung b√¨nh", "action": "Ngh·ªâ ng∆°i, u·ªëng nhi·ªÅu n∆∞·ªõc, ƒëi kh√°m n·∫øu ho k√©o d√†i."},
    "R·ªëi lo·∫°n ti√™u h√≥a": {"severity": "Th·∫•p", "action": "ƒÇn u·ªëng ƒëi·ªÅu ƒë·ªô, tr√°nh ƒë·ªì ƒÉn kh√≥ ti√™u, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu k√©o d√†i."},
    "Vi√™m kh·ªõp": {"severity": "Trung b√¨nh", "action": "Gi·ªØ ·∫•m kh·ªõp, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© ƒë·ªÉ d√πng thu·ªëc gi·∫£m ƒëau."},
    "Vi√™m ru·ªôt": {"severity": "Trung b√¨nh", "action": "ƒÇn u·ªëng nh·∫π nh√†ng, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu ƒëau b·ª•ng k√©o d√†i."},
    "Vi√™m t·ª•y": {"severity": "Cao", "action": "ƒêi kh√°m ngay t·∫°i b·ªánh vi·ªán, tr√°nh t·ª± ƒëi·ªÅu tr·ªã."},
    "Vi√™m gan": {"severity": "Cao", "action": "ƒêi kh√°m ngay, tu√¢n th·ªß ch·∫ø ƒë·ªô ƒÉn u·ªëng theo ch·ªâ d·∫´n b√°c sƒ©."},
    "Ch√†m": {"severity": "Th·∫•p", "action": "Gi·ªØ da s·∫°ch, d√πng kem d∆∞·ª°ng ·∫©m, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu n·∫∑ng."},
    "Vi√™m tai gi·ªØa": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m tai m≈©i h·ªçng, tr√°nh ƒë·ªÉ n∆∞·ªõc v√†o tai."},
    "Vi√™m da": {"severity": "Th·∫•p", "action": "Gi·ªØ da s·∫°ch, tr√°nh ch·∫•t k√≠ch ·ª©ng, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu n·∫∑ng."},
    "Vi√™m thanh qu·∫£n": {"severity": "Th·∫•p", "action": "Ngh·ªâ ng∆°i gi·ªçng n√≥i, u·ªëng nhi·ªÅu n∆∞·ªõc, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu k√©o d√†i."},
    "D·ªã ·ª©ng": {"severity": "Th·∫•p", "action": "Tr√°nh t√°c nh√¢n g√¢y d·ªã ·ª©ng, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu n·∫∑ng."},
    "T√°o b√≥n m√£n t√≠nh": {"severity": "Th·∫•p", "action": "TƒÉng c∆∞·ªùng ch·∫•t x∆°, u·ªëng nhi·ªÅu n∆∞·ªõc, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu k√©o d√†i."},
    "Vi√™m d·∫° d√†y": {"severity": "Trung b√¨nh", "action": "ƒÇn nh·∫π, tr√°nh ƒë·ªì chua cay, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu ƒëau k√©o d√†i."},
    "ƒê·ªôt qu·ªµ nh·∫π": {"severity": "Cao", "action": "ƒêi kh√°m ngay t·∫°i b·ªánh vi·ªán, kh√¥ng t·ª± ƒëi·ªÅu tr·ªã."},
    "Vi√™m m√†ng n√£o": {"severity": "Cao", "action": "ƒêi kh√°m ngay t·∫°i b·ªánh vi·ªán, kh√¥ng t·ª± ƒëi·ªÅu tr·ªã."},
    "M·∫•t ng·ªß": {"severity": "Th·∫•p", "action": "Duy tr√¨ th√≥i quen ng·ªß ƒë·ªÅu ƒë·∫∑n, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu k√©o d√†i."},
    "R·ªëi lo·∫°n lo √¢u": {"severity": "Trung b√¨nh", "action": "Tham kh·∫£o √Ω ki·∫øn b√°c sƒ© t√¢m l√Ω, th·ª±c h√†nh th∆∞ gi√£n."},
    "Zona th·∫ßn kinh": {"severity": "Trung b√¨nh", "action": "ƒêi kh√°m da li·ªÖu, d√πng thu·ªëc theo ch·ªâ ƒë·ªãnh b√°c sƒ©."},
    "Lo√©t d·∫° d√†y": {"severity": "Trung b√¨nh", "action": "ƒÇn u·ªëng ƒëi·ªÅu ƒë·ªô, tr√°nh cƒÉng th·∫≥ng, tham kh·∫£o √Ω ki·∫øn b√°c sƒ©."},
    "Vi√™m c∆° tim": {"severity": "Cao", "action": "ƒêi kh√°m ngay t·∫°i b·ªánh vi·ªán, kh√¥ng t·ª± ƒëi·ªÅu tr·ªã."},
    "Vi√™m ƒë·∫°i tr√†ng": {"severity": "Trung b√¨nh", "action": "ƒÇn u·ªëng l√†nh m·∫°nh, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu tri·ªáu ch·ª©ng n·∫∑ng."}
}

# Kh·ªüi t·∫°o df v√† hospital_df m·∫∑c ƒë·ªãnh
df = pd.read_excel("data_benh.xlsx")
hospital_df = pd.read_excel("benhviengoiy.xlsx")

# X·ª≠ l√Ω c·ªôt c·ªßa df v√† kh·ªüi t·∫°o symptom_columns, pre_existing_conditions
df.columns = df.columns.str.strip()
df.columns = df.columns.str.replace(r"\.\d+$", "", regex=True)
df = df.loc[:, ~df.columns.duplicated()]
symptom_columns = [col for col in df.columns if col.startswith("Tri·ªáu ch·ª©ng")]
pre_existing_conditions = [col for col in df.columns if col.startswith("Ti·ªÅn s·ª≠")]

st.session_state.symptom_columns = symptom_columns
st.session_state.pre_existing_conditions = pre_existing_conditions

# Sidebar cho t·∫£i file
with st.sidebar:
    st.header("üì§ T·∫£i D·ªØ Li·ªáu")
    uploaded_files = st.file_uploader(
        "T·∫£i 2 file: data_benh.xlsx v√† benhviengoiy.xlsx", 
        type=["xlsx"], 
        accept_multiple_files=True
    )

    if uploaded_files and len(uploaded_files) == 2:
        df_file = None
        hospital_file = None
        for file in uploaded_files:
            if "data_benh" in file.name.lower():
                df_file = file
            elif "benhviengoiy" in file.name.lower():
                hospital_file = file
        
        if df_file and hospital_file:
            df = pd.read_excel(df_file)
            hospital_df = pd.read_excel(hospital_file)
            st.success("T·∫£i 2 file th√†nh c√¥ng!")
            
            df.columns = df.columns.str.strip()
            df.columns = df.columns.str.replace(r"\.\d+$", "", regex=True)
            df = df.loc[:, ~df.columns.duplicated()]
            symptom_columns = [col for col in df.columns if col.startswith("Tri·ªáu ch·ª©ng")]
            pre_existing_conditions = [col for col in df.columns if col.startswith("Ti·ªÅn s·ª≠")]

            st.session_state.symptom_columns = symptom_columns
            st.session_state.pre_existing_conditions = pre_existing_conditions

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu to√†n c·ª•c
df['Gi·ªõi t√≠nh'] = df['Gi·ªõi t√≠nh'].astype(str).str.strip()
gender_mapping = {'0': 'Nam', '1': 'N·ªØ'}
valid_values = ['0', '1', 'Nam', 'N·ªØ']
if not df['Gi·ªõi t√≠nh'].isin(valid_values).all():
    invalid_genders = df[~df['Gi·ªõi t√≠nh'].isin(valid_values)]['Gi·ªõi t√≠nh'].unique()
    st.error(f"C·ªôt 'Gi·ªõi t√≠nh' ch·ª©a c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá: {invalid_genders}. Ch·ªâ ch·∫•p nh·∫≠n '0', '1', 'Nam', ho·∫∑c 'N·ªØ'.")
    st.stop()
df['Gi·ªõi t√≠nh'] = df['Gi·ªõi t√≠nh'].replace(gender_mapping)

le_gender = LabelEncoder()
df['Gi·ªõi t√≠nh'] = le_gender.fit_transform(df['Gi·ªõi t√≠nh'])
st.session_state.le_gender = le_gender

le_disease = LabelEncoder()
df['B·ªánh hi·ªán t·∫°i'] = le_disease.fit_transform(df['B·ªánh hi·ªán t·∫°i'].astype(str))
st.session_state.le_disease = le_disease

base_cols = ['Tu·ªïi', 'Gi·ªõi t√≠nh', 'B·ªánh hi·ªán t·∫°i']
binary_cols = [col for col in df.columns if df[col].dropna().isin([0, 1]).all() and col not in base_cols]

known_symptoms = [
    "S·ªët", "Ho", "ƒêau h·ªçng", "Kh√≥ th·ªü", "Ch·∫£y n∆∞·ªõc m≈©i", "Ngh·∫πt m≈©i", "ƒêau ƒë·∫ßu",
    "ƒêau ng·ª±c", "M·ªát m·ªèi", "Bu·ªìn n√¥n", "N√¥n", "Ti√™u ch·∫£y", "T√°o b√≥n", "ƒêau b·ª•ng",
    "·ªön l·∫°nh", "Ph√°t ban", "Ng·ª©a da", "Ch√≥ng m·∫∑t", "M·∫•t v·ªã gi√°c", "M·∫•t kh·ª©u gi√°c",
    "Lo √¢u", "Kh√≥ ng·ªß", "Kh√≥ nu·ªët", "S·ª•t c√¢n", "ƒê·ªï m·ªì h√¥i nhi·ªÅu"
]

symptom_columns = [col for col in binary_cols if col in known_symptoms]
pre_existing_conditions = [col for col in binary_cols if col not in symptom_columns]
feature_columns = list(dict.fromkeys(['Tu·ªïi', 'Gi·ªõi t√≠nh'] + symptom_columns + pre_existing_conditions))
st.session_state.feature_columns = feature_columns

# T·∫°o c√°c tab
tab1, tab2, tab3, tab4 = st.tabs(["üìä Ph√¢n t√≠ch d·ªØ li·ªáu", "ü§ñ D·ª± ƒëo√°n b·ªánh", "üîç Ph√¢n c·ª•m", "üí¨ Chatbox"])
# Tab 1: Xem d·ªØ li·ªáu
with tab1:
    st.header("Xem D·ªØ Li·ªáu")
    st.subheader("Ph√¢n B·ªë C√°c B·ªánh")
    disease_counts = df['B·ªánh hi·ªán t·∫°i'].value_counts().reset_index()
    disease_counts.columns = ["B·ªánh", "S·ªë l∆∞·ª£ng"]
    st.dataframe(disease_counts, use_container_width=True)
    fig = px.bar(disease_counts, x="B·ªánh", y="S·ªë l∆∞·ª£ng", 
                 text="S·ªë l∆∞·ª£ng", 
                 title="Ph√¢n B·ªë C√°c B·ªánh Trong D·ªØ Li·ªáu",
                 color="B·ªánh",
                 height=400)
    fig.update_traces(texttemplate='%{text}', textposition='auto')
    st.plotly_chart(fig, use_container_width=True)

    # Ph√¢n t√≠ch t∆∞∆°ng quan
    st.subheader("Ph√¢n T√≠ch T∆∞∆°ng Quan Gi·ªØa Tri·ªáu Ch·ª©ng/B·ªánh Ti·ªÅn S·ª≠ v√† B·ªánh")
    correlation_data = df[feature_columns + ['B·ªánh hi·ªán t·∫°i']].copy()
    correlation_data = pd.get_dummies(correlation_data, columns=['B·ªánh hi·ªán t·∫°i'])
    disease_cols = [col for col in correlation_data.columns if col.startswith('B·ªánh hi·ªán t·∫°i_')]
    correlation_results = {}
    for feature in feature_columns:
        correlations = {}
        for disease_col in disease_cols:
            disease_name = le_disease.inverse_transform([int(disease_col.split('_')[-1])])[0]
            corr = correlation_data[feature].corr(correlation_data[disease_col], method='pearson')
            if not np.isnan(corr) and abs(corr) > 0.1:
                correlations[disease_name] = corr
        if correlations:
            correlation_results[feature] = correlations

    # L∆∞u k·∫øt qu·∫£ t∆∞∆°ng quan v√†o session_state
    st.session_state.correlation_results = correlation_results

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ t∆∞∆°ng quan
    for feature, correlations in correlation_results.items():
        st.write(f"**{feature}**")
        for disease, corr in correlations.items():
            st.write(f"- {disease}: {corr:.3f}")

    st.subheader("D·ªØ li·ªáu b·ªánh")
    rows_per_page = st.selectbox("S·ªë d√≤ng m·ªói trang", options=[10, 20, 50, 100], index=0)
    total_rows = len(df)
    total_pages = (total_rows // rows_per_page) + (1 if total_rows % rows_per_page else 0)
    page = st.number_input("Trang", min_value=1, max_value=total_pages, value=1, step=1)
    start_idx = (page - 1) * rows_per_page
    end_idx = start_idx + rows_per_page
    page_data = df.iloc[start_idx:end_idx]
    st.dataframe(page_data, height=300, use_container_width=True)
    st.markdown(f"ƒêang hi·ªÉn th·ªã trang {page}/{total_pages} ({start_idx + 1} - {min(end_idx, total_rows)} tr√™n {total_rows} d√≤ng)")

    st.subheader("D·ªØ li·ªáu b·ªánh vi·ªán")
    st.dataframe(hospital_df, height=300, use_container_width=True)

# Tab 2: D·ª± ƒëo√°n m√¥ h√¨nh
with tab2:
    st.header("D·ª± ƒëo√°n m√¥ h√¨nh")

    # Ti·ªÅn x·ª≠ l√Ω
    X = df[feature_columns]
    y = df['B·ªánh hi·ªán t·∫°i']
    
    use_smote = st.checkbox("S·ª≠ d·ª•ng SMOTE ƒë·ªÉ c√¢n b·∫±ng d·ªØ li·ªáu", value=True)

    if use_smote:
        smote = SMOTE(random_state=42)
        X_resampled, y_resampled = smote.fit_resample(X, y)
    else:
        X_resampled, y_resampled = X, y

    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

    # Hu·∫•n luy·ªán m√¥ h√¨nh
    models = {
        "Decision Tree": DecisionTreeClassifier(random_state=42, class_weight='balanced'),
        "Random Forest": RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced')
    }
    model_results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
        model_results[name] = {
            "model": model,
            "accuracy": accuracy,
            "report": report
        }
    st.session_state.model_results = model_results

    st.subheader("T·ªïng H·ª£p ƒê·ªô Ch√≠nh X√°c")
    accuracy_df = pd.DataFrame({
        "M√¥ H√¨nh": [name for name in model_results.keys()],
        "ƒê·ªô Ch√≠nh X√°c": [result["accuracy"] for result in model_results.values()]
    })
    st.dataframe(accuracy_df, use_container_width=True)

    fig = px.bar(accuracy_df, x="M√¥ H√¨nh", y="ƒê·ªô Ch√≠nh X√°c", 
                 text="ƒê·ªô Ch√≠nh X√°c", 
                 title="So S√°nh ƒê·ªô Ch√≠nh X√°c C·ªßa C√°c M√¥ H√¨nh",
                 color="M√¥ H√¨nh",
                 height=400)
    fig.update_traces(texttemplate='%{text:.4f}', textposition='auto')
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("Chi Ti·∫øt B√°o C√°o Ph√¢n Lo·∫°i")
    cols = st.columns(2)
    for idx, (name, result) in enumerate(model_results.items()):
        with cols[idx]:
            with st.expander(f"B√°o C√°o Ph√¢n Lo·∫°i: {name}"):
                report_df = pd.DataFrame({
                    "L·ªõp": [str(k) for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']],
                    "Precision": [result["report"][k]["precision"] for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']],
                    "Recall": [result["report"][k]["recall"] for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']],
                    "F1-Score": [result["report"][k]["f1-score"] for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']],
                    "Support": [result["report"][k]["support"] for k in result["report"].keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]
                })
                st.dataframe(report_df, use_container_width=True)
                st.write(f"**ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ**: {result['accuracy']:.4f}")

    st.subheader("üîç D·ª± ƒêo√°n B·ªánh T·ª´ Tri·ªáu Ch·ª©ng")
    st.markdown("Nh·∫≠p th√¥ng tin ƒë·ªÉ d·ª± ƒëo√°n b·ªánh.")
    with st.form("symptom_form"):
        age = st.number_input("Tu·ªïi", min_value=0, max_value=120, value=30)
        gender = st.selectbox("Gi·ªõi t√≠nh", options=["Nam", "N·ªØ"])
        region = st.selectbox("Khu v·ª±c", options=["Mi·ªÅn B·∫Øc", "Mi·ªÅn Trung", "Mi·ªÅn Nam"])
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Ch·ªçn Tri·ªáu Ch·ª©ng**")
            with st.container(height=300):
                symptoms = {}
                for col in symptom_columns:
                    default_value = False if st.session_state.reset_symptom_form else st.session_state.get(f"symptom_{col}", False)
                    symptoms[col] = st.checkbox(col, value=default_value, key=f"symptom_{col}")
        with col2:
            st.markdown("**Ch·ªçn B·ªánh Ti·ªÅn S·ª≠**")
            with st.container(height=300):
                conditions = {}
                for condition in pre_existing_conditions:
                    default_value = False if st.session_state.reset_symptom_form else st.session_state.get(f"condition_{condition}", False)
                    conditions[condition] = st.checkbox(condition, value=default_value, key=f"condition_{condition}")
        col_submit, col_reset = st.columns([1, 1])
        with col_submit:
            submitted = st.form_submit_button("D·ª± ƒëo√°n")
        with col_reset:
            reset = st.form_submit_button("Reset Tri·ªáu Ch·ª©ng")

        if reset:
            st.session_state.reset_symptom_form = True
            st.rerun()

        if st.session_state.reset_symptom_form:
            st.session_state.reset_symptom_form = False

        if submitted:
            if not st.session_state.model_results or not st.session_state.le_disease or not st.session_state.le_gender:
                st.error("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc!")
                st.stop()
            try:
                input_data = pd.DataFrame(columns=st.session_state.feature_columns)
                input_data.loc[0, 'Tu·ªïi'] = age
                gender_normalized = gender.strip().capitalize()
                input_data.loc[0, 'Gi·ªõi t√≠nh'] = st.session_state.le_gender.transform([gender_normalized])[0]
                for col in symptom_columns:
                    input_data.loc[0, col] = 1 if symptoms[col] else 0
                for condition in pre_existing_conditions:
                    input_data.loc[0, condition] = 1 if conditions[condition] else 0
                input_data = input_data.fillna(0).infer_objects(copy=False).astype(int)

                num_symptoms = sum(1 for col, val in symptoms.items() if val)
                if num_symptoms < 2:
                    st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t 2 tri·ªáu ch·ª©ng ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c h∆°n.")
                    st.stop()

                light_diseases = ["C√∫m", "Vi√™m h·ªçng", "Vi√™m amidan"]
                severe_symptoms = ["Kh√≥ th·ªü", "ƒêau ng·ª±c", "M·∫•t v·ªã gi√°c", "M·∫•t kh·ª©u gi√°c"]
                has_severe_symptom = any(symptoms[symptom] for symptom in severe_symptoms)

                st.write("#### K·∫øt Qu·∫£ D·ª± ƒêo√°n")
                all_diseases = []
                model_predictions = {}
                top_disease_for_hospital = None
                for name, result in st.session_state.model_results.items():
                    model = result["model"]
                    model_predictions[name] = []
                    st.write(f"**{name}**:")
                    if hasattr(model, "predict_proba"):
                        probs = model.predict_proba(input_data)[0]
                        # ƒêi·ªÅu ch·ªânh x√°c su·∫•t d·ª±a tr√™n t∆∞∆°ng quan
                        adjusted_probs = probs.copy()
                        correlation_adjustments = []
                        if 'correlation_results' in st.session_state:
                            for feature in feature_columns:
                                if (feature in symptoms and symptoms[feature]) or (feature in conditions and conditions[feature]):
                                    if feature in st.session_state.correlation_results:
                                        for disease, corr in st.session_state.correlation_results[feature].items():
                                            if disease in st.session_state.le_disease.classes_:
                                                disease_idx = np.where(st.session_state.le_disease.classes_ == disease)[0]
                                                if len(disease_idx) > 0:
                                                    old_prob = adjusted_probs[disease_idx[0]]
                                                    new_prob = old_prob + (old_prob * corr * 0.5)
                                                    adjusted_probs[disease_idx[0]] = new_prob
                                                    correlation_adjustments.append({
                                                        "Feature": feature,
                                                        "B·ªánh": disease,
                                                        "T∆∞∆°ng quan": f"{corr:.3f}",
                                                        "TƒÉng x√°c su·∫•t": f"{disease}: t·ª´ {old_prob:.2%} l√™n {new_prob:.2%}"
                                                    })
                        adjusted_probs = adjusted_probs / adjusted_probs.sum()

                        # ƒêi·ªÅu ch·ªânh x√°c su·∫•t n·∫øu s·ªë l∆∞·ª£ng tri·ªáu ch·ª©ng <= 4 v√† kh√¥ng c√≥ tri·ªáu ch·ª©ng ƒë·∫∑c tr∆∞ng
                        if num_symptoms <= 4 and not has_severe_symptom:
                            for idx, disease in enumerate(st.session_state.le_disease.classes_):
                                if disease in light_diseases:
                                    adjusted_probs[idx] *= 3.0
                            adjusted_probs = adjusted_probs / adjusted_probs.sum()

                        top_indices = np.argsort(adjusted_probs)[-3:][::-1]
                        model_diseases = [(st.session_state.le_disease.inverse_transform([i])[0], adjusted_probs[i]) for i in top_indices]
                        for disease, prob in model_diseases:
                            st.write(f"- {disease}: {prob:.2%}")
                            model_predictions[name].append((disease, prob))
                        st.success(f"‚úÖ D·ª± ƒëo√°n ch√≠nh: **{model_diseases[0][0]}** v·ªõi x√°c su·∫•t {model_diseases[0][1]:.2%}")
                        all_diseases.extend([(disease, prob, name) for disease, prob in model_diseases])
                        if name == "Random Forest":
                            top_disease_for_hospital = model_diseases[0][0]
                    else:
                        prediction = model.predict(input_data)
                        predicted_disease = st.session_state.le_disease.inverse_transform(prediction)[0]
                        st.write(f"{predicted_disease} (m√¥ h√¨nh kh√¥ng h·ªó tr·ª£ x√°c su·∫•t)")
                        model_predictions[name].append((predicted_disease, 0.0))
                        all_diseases.append((predicted_disease, 0.0, name))

                rf_diseases = sorted(model_predictions["Random Forest"], key=lambda x: x[1], reverse=True)[:2]
                final_diseases = [(disease, prob, "Random Forest") for disease, prob in rf_diseases]
                rf_diseases_set = set(disease for disease, _, _ in final_diseases)

                other_diseases = [(disease, prob, model) for disease, prob, model in all_diseases if model == "Decision Tree" and disease not in rf_diseases_set]
                if other_diseases:
                    other_diseases = sorted(other_diseases, key=lambda x: x[1], reverse=True)
                    final_diseases.append(other_diseases[0])
                else:
                    if len(model_predictions["Random Forest"]) > 2:
                        third_rf_disease = sorted(model_predictions["Random Forest"], key=lambda x: x[1], reverse=True)[2]
                        if third_rf_disease[0] not in rf_diseases_set:
                            final_diseases.append((third_rf_disease[0], third_rf_disease[1], "Random Forest"))

                final_diseases = sorted(final_diseases, key=lambda x: x[1], reverse=True)[:3]

                colors = ["#28a745", "#fd7e14", "#6f42c1"]

                st.markdown("### ü©∫ **K·∫øt Qu·∫£ T∆∞ V·∫•n C√° Nh√¢n H√≥a**")
                st.markdown(f"""
                **Th√¥ng tin ng∆∞·ªùi d√πng:**
                - Tu·ªïi: {age}
                - Gi·ªõi t√≠nh: {gender}
                - Khu v·ª±c: {region}
                - Tri·ªáu ch·ª©ng: {', '.join([col for col, val in symptoms.items() if val]) or 'Kh√¥ng c√≥'}
                - B·ªánh ti·ªÅn s·ª≠: {', '.join([cond for cond, val in conditions.items() if val]) or 'Kh√¥ng c√≥'}

                **M√¥ h√¨nh d·ª± ƒëo√°n:**
                K·∫øt qu·∫£ d·ª± ƒëo√°n ch√≠nh l√†:
                """)
                for idx, (disease, prob, model) in enumerate(final_diseases):
                    st.markdown(f"- <span style='color:{colors[idx]}'>{disease}</span>", unsafe_allow_html=True)
                st.markdown("- D·ª±a tr√™n t·ªï h·ª£p c√°c tri·ªáu ch·ª©ng v√† ti·ªÅn s·ª≠ b·ªánh li√™n quan")

                st.markdown("**G·ª£i √Ω h√†nh ƒë·ªông:**")
                for disease, prob, model in final_diseases:
                    hospitals, severity, action = suggest_hospitals_and_actions(disease, hospital_df, action_dict, region)
                    with st.container():
                        st.markdown(f"""
                        <div class="suggestion-box">
                            <h4>B·ªánh: {disease} ({prob:.2%})</h4>
                            <p><strong>M·ª©c ƒë·ªô nghi√™m tr·ªçng:</strong> {severity}</p>
                            <p><strong>H√†nh ƒë·ªông:</strong> {action}</p>
                            <p><strong>B·ªánh vi·ªán g·ª£i √Ω:</strong> {', '.join(hospitals)}</p>
                        </div>
                        """, unsafe_allow_html=True)
                st.info("‚ö†Ô∏è ƒê√¢y ch·ªâ l√† g·ª£i √Ω t·ª´ m√¥ h√¨nh h·ªçc m√°y. H√£y ƒë·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c kh√°m v√† ch·∫©n ƒëo√°n ch√≠nh x√°c.")

            except ValueError as e:
                st.error(f"L·ªói khi d·ª± ƒëo√°n: {str(e)}. Vui l√≤ng ki·ªÉm tra gi√° tr·ªã ƒë·∫ßu v√†o.")
                st.stop()

# Tab 3: Ph√¢n c·ª•m
with tab3:
    st.header("üîç D·ª± ƒêo√°n B·ªánh B·∫±ng Ph√¢n C·ª•m v√† Lu·∫≠t K·∫øt H·ª£p")

    X = df[feature_columns]
    y = df['B·ªánh hi·ªán t·∫°i']

    try:
        smote = SMOTE(random_state=42)
        X_resampled, y_resampled = smote.fit_resample(X, y)
        df_resampled = pd.DataFrame(X_resampled, columns=feature_columns)
        df_resampled['B·ªánh hi·ªán t·∫°i'] = y_resampled
    except ValueError:
        X_resampled, y_resampled = X, y
        df_resampled = df.copy()

    num_clusters = st.slider("S·ªë l∆∞·ª£ng c·ª•m", min_value=3, max_value=15, value=7)

    st.subheader("‚öôÔ∏è C·∫•u H√¨nh Apriori")
    min_support = st.slider("Min Support", min_value=0.01, max_value=0.5, value=0.05, step=0.01, format="%.2f")
    min_confidence = st.slider("Min Confidence", min_value=0.1, max_value=1.0, value=0.6, step=0.1, format="%.1f")
    min_lift = st.slider("Min Lift", min_value=1.0, max_value=10.0, value=1.0, step=0.1, format="%.1f")

    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X_resampled)
    df_resampled['C·ª•m'] = cluster_labels
    st.session_state.clusters = cluster_labels

    st.subheader("üìú T√¨m Lu·∫≠t K·∫øt H·ª£p Trong T·ª´ng C·ª•m")
    cluster_rules = {}
    for cluster in range(num_clusters):
        cluster_data = df_resampled[df_resampled['C·ª•m'] == cluster]
        if len(cluster_data) < 2:
            cluster_rules[cluster] = []
            continue

        transactions = []
        for idx, row in cluster_data.iterrows():
            transaction = []
            for col in symptom_columns:
                if row[col] == 1:
                    transaction.append(col)
            for col in pre_existing_conditions:
                if row[col] == 1:
                    transaction.append(col)
            disease = st.session_state.le_disease.inverse_transform([row['B·ªánh hi·ªán t·∫°i']])[0]
            transaction.append(f"B·ªánh_{disease}")
            transactions.append(transaction)

        if not transactions:
            cluster_rules[cluster] = []
            continue
        transaction_binary = pd.DataFrame(0, index=range(len(transactions)), columns=np.unique(np.concatenate(transactions)))
        for idx, transaction in enumerate(transactions):
            for item in transaction:
                transaction_binary.loc[idx, item] = 1

        frequent_itemsets_df = apriori(transaction_binary, min_support=min_support, use_colnames=True)
        if frequent_itemsets_df.empty:
            cluster_rules[cluster] = []
            continue

        rules = association_rules(frequent_itemsets_df, metric="confidence", min_threshold=min_confidence)
        rules = rules[rules['lift'] >= min_lift]
        cluster_rules[cluster] = rules

    st.session_state.cluster_rules = cluster_rules

    st.subheader("üìä Th√¥ng Tin V·ªÅ C√°c C·ª•m")
    for cluster in range(num_clusters):
        cluster_data = df_resampled[df_resampled['C·ª•m'] == cluster]
        with st.expander(f"C·ª•m {cluster} ({len(cluster_data)} b·ªánh nh√¢n)"):
            symptom_means = cluster_data[symptom_columns].mean().sort_values(ascending=False)
            top_symptoms = symptom_means.head(2)
            symptom_df = pd.DataFrame({
                "Tri·ªáu ch·ª©ng": top_symptoms.index,
                "T·ª∑ l·ªá": [f"{value:.2%}" for value in top_symptoms.values]
            })
            st.write("**Tri·ªáu ch·ª©ng ph·ªï bi·∫øn nh·∫•t:**")
            st.dataframe(symptom_df, use_container_width=True, hide_index=True)

            condition_means = cluster_data[pre_existing_conditions].mean().sort_values(ascending=False)
            top_conditions = condition_means.head(2)
            condition_df = pd.DataFrame({
                "B·ªánh ti·ªÅn s·ª≠": top_conditions.index,
                "T·ª∑ l·ªá": [f"{value:.2%}" for value in top_conditions.values]
            })
            st.write("**B·ªánh ti·ªÅn s·ª≠ ph·ªï bi·∫øn nh·∫•t:**")
            st.dataframe(condition_df, use_container_width=True, hide_index=True)

            disease_counts = cluster_data['B·ªánh hi·ªán t·∫°i'].value_counts().head(2)
            disease_df = pd.DataFrame({
                "B·ªánh": [st.session_state.le_disease.inverse_transform([idx])[0] for idx in disease_counts.index],
                "S·ªë b·ªánh nh√¢n": disease_counts.values,
                "T·ª∑ l·ªá": [f"{count/len(cluster_data):.2%}" for count in disease_counts.values]
            })
            st.write("**B·ªánh ph·ªï bi·∫øn nh·∫•t:**")
            st.dataframe(disease_df, use_container_width=True, hide_index=True)

            rules = cluster_rules.get(cluster, [])
            if not rules.empty:
                st.write("**Lu·∫≠t k·∫øt h·ª£p ph·ªï bi·∫øn nh·∫•t:**")
                rule_display = []
                for idx, row in rules.head(3).iterrows():
                    antecedents = list(row['antecedents'])
                    consequents = list(row['consequents'])
                    confidence = row['confidence']
                    lift = row['lift']
                    rule_display.append({
                        "ƒêi·ªÅu ki·ªán": ", ".join(antecedents),
                        "K·∫øt lu·∫≠n": ", ".join(consequents),
                        "ƒê·ªô tin c·∫≠y": f"{confidence:.2%}",
                        "ƒê·ªô n√¢ng": f"{lift:.2f}"
                    })
                st.dataframe(pd.DataFrame(rule_display), use_container_width=True, hide_index=True)
            else:
                st.write("Kh√¥ng t√¨m th·∫•y lu·∫≠t k·∫øt h·ª£p n√†o trong c·ª•m n√†y.")

    st.subheader("üîç D·ª± ƒêo√°n B·ªánh T·ª´ C·ª•m")
    with st.form("cluster_prediction_form"):
        age = st.number_input("Tu·ªïi", min_value=0, max_value=120, value=30, key="cluster_age")
        gender = st.selectbox("Gi·ªõi t√≠nh", options=["Nam", "N·ªØ"], key="cluster_gender")
        region = st.selectbox("Khu v·ª±c", options=["Mi·ªÅn B·∫Øc", "Mi·ªÅn Trung", "Mi·ªÅn Nam"], key="cluster_region")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Ch·ªçn Tri·ªáu Ch·ª©ng**")
            with st.container(height=300):
                cluster_symptoms = {}
                for col in symptom_columns:
                    default_value = False if st.session_state.reset_cluster_form else st.session_state.get(f"cluster_symptom_{col}", False)
                    cluster_symptoms[col] = st.checkbox(col, value=default_value, key=f"cluster_symptom_{col}")
        with col2:
            st.markdown("**Ch·ªçn B·ªánh Ti·ªÅn S·ª≠**")
            with st.container(height=300):
                cluster_conditions = {}
                for condition in pre_existing_conditions:
                    default_value = False if st.session_state.reset_cluster_form else st.session_state.get(f"cluster_condition_{condition}", False)
                    cluster_conditions[condition] = st.checkbox(condition, value=default_value, key=f"cluster_condition_{condition}")
        
        col_submit, col_reset = st.columns([1, 1])
        with col_submit:
            submitted = st.form_submit_button("üîç D·ª± ƒëo√°n t·ª´ c·ª•m")
        with col_reset:
            reset = st.form_submit_button("Reset Tri·ªáu Ch·ª©ng")
        
        if reset:
            st.session_state.reset_cluster_form = True
            st.rerun()
        
        if st.session_state.reset_cluster_form:
            st.session_state.reset_cluster_form = False
        
        if submitted:
            input_data = pd.DataFrame(columns=feature_columns)
            input_data.loc[0, 'Tu·ªïi'] = age
            gender_normalized = gender.strip().capitalize()
            input_data.loc[0, 'Gi·ªõi t√≠nh'] = st.session_state.le_gender.transform([gender_normalized])[0]
            for col in symptom_columns:
                input_data.loc[0, col] = 1 if cluster_symptoms[col] else 0
            for condition in pre_existing_conditions:
                input_data.loc[0, condition] = 1 if cluster_conditions[condition] else 0
            input_data = input_data.fillna(0).infer_objects(copy=False).astype(int)

            num_symptoms = sum(1 for col, val in cluster_symptoms.items() if val)
            if num_symptoms < 3:
                st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t 3 tri·ªáu ch·ª©ng ƒë·ªÉ tƒÉng kh·∫£ nƒÉng t√¨m lu·∫≠t k·∫øt h·ª£p.")
                st.stop()

            cluster_assignment = kmeans.predict(input_data)[0]
            st.write(f"Tri·ªáu ch·ª©ng ƒë·∫ßu v√†o thu·ªôc **C·ª•m {cluster_assignment}**")

            cluster_data = df_resampled[df_resampled['C·ª•m'] == cluster_assignment]
            if len(cluster_data) < 2:
                st.warning("‚ö†Ô∏è C·ª•m n√†y c√≥ qu√° √≠t d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n ch√≠nh x√°c. Vui l√≤ng th·ª≠ v·ªõi s·ªë l∆∞·ª£ng c·ª•m kh√°c.")
                st.stop()
            disease_counts = cluster_data['B·ªánh hi·ªán t·∫°i'].value_counts()
            st.write("**Ph√¢n b·ªë b·ªánh trong c·ª•m:**")
            disease_distribution = pd.DataFrame({
                "B·ªánh": [st.session_state.le_disease.inverse_transform([idx])[0] for idx in disease_counts.index],
                "S·ªë b·ªánh nh√¢n": disease_counts.values,
                "T·ª∑ l·ªá": [f"{count/len(cluster_data):.2%}" for count in disease_counts.values]
            })
            st.dataframe(disease_distribution, use_container_width=True, hide_index=True)

            X_cluster = cluster_data[feature_columns]
            y_cluster = cluster_data['B·ªánh hi·ªán t·∫°i']

            lr = LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial', class_weight='balanced')
            lr.fit(X_cluster, y_cluster)

            probs = lr.predict_proba(input_data)[0]

            matched_rules = []
            if st.session_state.cluster_rules and cluster_assignment in st.session_state.cluster_rules:
                rules = st.session_state.cluster_rules[cluster_assignment]
                if not rules.empty:
                    input_items = [col for col, val in cluster_symptoms.items() if val]
                    input_items += [col for col, val in cluster_conditions.items() if val]
                    input_set = set(input_items)
                    
                    for idx, row in rules.iterrows():
                        antecedents = set(row['antecedents'])
                        consequents = set(row['consequents'])
                        confidence = row['confidence']
                        matched_items = len(antecedents.intersection(input_set))
                        match_ratio = matched_items / len(antecedents) if len(antecedents) > 0 else 0
                        if match_ratio >= 0.5:
                            for consequent in consequents:
                                if consequent.startswith("B·ªánh_"):
                                    disease = consequent.replace("B·ªánh_", "")
                                    matched_rules.append({
                                        "disease": disease,
                                        "confidence": confidence * match_ratio,
                                        "antecedents": ", ".join(antecedents),
                                        "match_ratio": match_ratio
                                    })

            if matched_rules:
                st.write("**Lu·∫≠t k·∫øt h·ª£p kh·ªõp v·ªõi tri·ªáu ch·ª©ng ƒë·∫ßu v√†o (tham kh·∫£o):**")
                rule_display = []
                for rule in matched_rules:
                    disease = rule['disease']
                    confidence = rule['confidence']
                    antecedents = rule['antecedents']
                    match_ratio = rule['match_ratio']
                    rule_display.append({
                        "ƒêi·ªÅu ki·ªán": antecedents,
                        "K·∫øt lu·∫≠n": disease,
                        "ƒê·ªô tin c·∫≠y": f"{confidence:.2%}",
                        "T·ª∑ l·ªá kh·ªõp": f"{match_ratio:.0%}"
                    })
                st.dataframe(pd.DataFrame(rule_display), use_container_width=True, hide_index=True)

            adjusted_probs = probs + 1e-3
            adjusted_probs = adjusted_probs / adjusted_probs.sum()

            top_indices = np.argsort(adjusted_probs)[-3:][::-1]
            top_diseases = [(st.session_state.le_disease.inverse_transform([i])[0], adjusted_probs[i]) for i in top_indices]

            st.write("**K·∫øt qu·∫£ d·ª± ƒëo√°n:**")
            for disease, prob in top_diseases:
                st.write(f"- {disease}: {prob:.2%}")
            st.success(f"‚úÖ D·ª± ƒëo√°n ch√≠nh: **{top_diseases[0][0]}** v·ªõi x√°c su·∫•t {top_diseases[0][1]:.2%}")

            st.write("**Tri·ªáu ch·ª©ng quan tr·ªçng nh·∫•t ·∫£nh h∆∞·ªüng ƒë·∫øn d·ª± ƒëo√°n:**")
            feature_importance = pd.Series(lr.coef_[lr.classes_ == top_indices[0]][0], index=feature_columns)
            top_features = feature_importance.sort_values(ascending=False).head(3)
            for feature, coef in top_features.items():
                st.write(f"- {feature}: h·ªá s·ªë {coef:.3f}")

            st.markdown("**G·ª£i √Ω b·ªánh vi·ªán v√† h√†nh ƒë·ªông cho c√°c b·ªánh d·ª± ƒëo√°n:**")
            for idx, (disease, prob) in enumerate(top_diseases):
                hospitals, severity, action = suggest_hospitals_and_actions(disease, hospital_df, action_dict, region)
                with st.container():
                    st.markdown(f"""
                    <div class="suggestion-box">
                        <h4>B·ªánh: {disease} ({prob:.2%})</h4>
                        <p><strong>M·ª©c ƒë·ªô nghi√™m tr·ªçng:</strong> {severity}</p>
                        <p><strong>H√†nh ƒë·ªông:</strong> {action}</p>
                        <p><strong>B·ªánh vi·ªán g·ª£i √Ω:</strong> {', '.join(hospitals)}</p>
                    </div>
                    """, unsafe_allow_html=True)
            st.info("‚ö†Ô∏è ƒê√¢y ch·ªâ l√† g·ª£i √Ω t·ª´ ph∆∞∆°ng ph√°p ph√¢n c·ª•m v√† lu·∫≠t k·∫øt h·ª£p. H√£y ƒë·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c kh√°m v√† ch·∫©n ƒëo√°n ch√≠nh x√°c.")
# Tab 4: Chatbox
# Tab 4: Chatbox
with tab4:
    st.header("üí¨ T∆∞ V·∫•n S·ª©c Kh·ªèe T·ª± ƒê·ªông")
    st.markdown("H√£y nh·∫≠p c√¢u h·ªèi m√¥ t·∫£ tri·ªáu ch·ª©ng, v√≠ d·ª•: `T√¥i b·ªã ho v√† s·ªët 2 ng√†y nay.`")

    region = st.selectbox("üåç Ch·ªçn khu v·ª±c b·∫°n s·ªëng", ["Mi·ªÅn B·∫Øc", "Mi·ªÅn Trung", "Mi·ªÅn Nam"], key="chat_region")

    age = st.number_input("üéÇ Tu·ªïi c·ªßa b·∫°n", min_value=0, max_value=120, value=30, step=1, key="chat_age")
    gender = st.radio("üë§ Gi·ªõi t√≠nh c·ªßa b·∫°n", ["Nam", "N·ªØ"], key="chat_gender")

    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []

    user_input = st.text_input("üßë B·∫°n:", placeholder="T√¥i b·ªã ƒëau h·ªçng v√† kh√≥ th·ªü...")

    def normalize_text(text):
        import unicodedata
        return ''.join(c for c in unicodedata.normalize('NFD', text.lower()) if unicodedata.category(c) != 'Mn')

    def generate_chatbot_response(message, age, gender, region):
        if not st.session_state.model_results or "Random Forest" not in st.session_state.model_results:
            return "‚ö†Ô∏è M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng v√†o tab 'D·ª± ƒëo√°n b·ªánh' ƒë·ªÉ hu·∫•n luy·ªán tr∆∞·ªõc."

        message = normalize_text(message)
        found_symptoms = [symptom for symptom in symptom_columns if normalize_text(symptom) in message]

        if not found_symptoms:
            return "ü§ñ T√¥i ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c tri·ªáu ch·ª©ng n√†o r√µ r√†ng. B·∫°n c√≥ th·ªÉ m√¥ t·∫£ c·ª• th·ªÉ h∆°n kh√¥ng?"

        input_data = {col: 0 for col in feature_columns}
        for symptom in found_symptoms:
            input_data[symptom] = 1
        input_data["Tu·ªïi"] = age
        input_data["Gi·ªõi t√≠nh"] = st.session_state.le_gender.transform([gender])[0]

        input_df = pd.DataFrame([input_data])

        model = st.session_state.model_results["Random Forest"]["model"]
        probs = model.predict_proba(input_df)[0]
        top_idx = probs.argmax()
        disease = st.session_state.le_disease.inverse_transform([top_idx])[0]
        confidence = probs[top_idx]

        action_info = action_dict.get(disease, {
            "severity": "Ch∆∞a r√µ",
            "action": "Vui l√≤ng ƒë·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n c·ª• th·ªÉ."
        })

        matches = hospital_df[(hospital_df["B·ªánh"] == disease) & (hospital_df["Khu v·ª±c"] == region)]
        hospitals = matches["B·ªánh vi·ªán"].dropna().tolist()
        if not hospitals:
            hospitals = ["Kh√¥ng c√≥ b·ªánh vi·ªán g·ª£i √Ω trong khu v·ª±c. H√£y ƒë·∫øn c∆° s·ªü y t·∫ø g·∫ßn nh·∫•t."]

        return (
            f"ü©∫ **CH·∫®N ƒêO√ÅN C√ì TH·ªÇ: {disease.upper()}**\n\n"
            f"üìõ **M·ª©c ƒë·ªô nghi√™m tr·ªçng:** {action_info['severity']}\n\n"
            f"üìå **H∆∞·ªõng x·ª≠ l√Ω:** {action_info['action']}\n\n"
            f"üè• **G·ª£i √Ω b·ªánh vi·ªán ({region}):** {', '.join(hospitals)}"
        )

    if st.button("üì® G·ª≠i"):
        if user_input.strip() != "":
            reply = generate_chatbot_response(user_input, age, gender, region)
            st.session_state.chat_history.append(("üßë B·∫°n", user_input))
            st.session_state.chat_history.append(("ü§ñ H·ªá th·ªëng", reply))
            user_input = ""

    if st.session_state.chat_history:
        st.markdown("---")
        st.subheader("üìú L·ªãch s·ª≠ tr√≤ chuy·ªán")
        for sender, msg in st.session_state.chat_history[-6:]:  # Hi·ªÉn th·ªã 6 d√≤ng g·∫ßn nh·∫•t
            if sender == "üßë B·∫°n":
                st.markdown(f"**{sender}:** {msg}")
            else:
                st.markdown(
                    f"<div style='background-color:#f1f1f1;padding:10px;border-radius:8px;margin-bottom:8px'>"
                    f"<strong>{sender}:</strong><br>{msg}</div>",
                    unsafe_allow_html=True
                )
